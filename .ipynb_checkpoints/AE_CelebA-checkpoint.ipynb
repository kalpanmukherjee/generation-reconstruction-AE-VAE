{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f36dea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os # for pulling up images and annotations\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec8bc1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "device = \"mps\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7d815d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_dim = 128 * 128 \n",
    "latent_dim = 1024  # Size of the latent space\n",
    "batch_size = 64\n",
    "epochs = 20\n",
    "lr = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dc4771",
   "metadata": {},
   "source": [
    "## Count number of images available in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70f2093d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_num_files_in_directory(directory):\n",
    "    # List the files in the directory\n",
    "    file_list = os.listdir(directory)\n",
    "\n",
    "    # Count the number of files, ignoring subdirectories\n",
    "    file_count = sum(os.path.isfile(os.path.join(directory, f)) for f in file_list)\n",
    "    return file_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfcb2493",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num images:  202599\n"
     ]
    }
   ],
   "source": [
    "# Specify the directory you want to count the files for\n",
    "directory = 'CelebA/Img/img_align_celeba/'\n",
    "\n",
    "number_of_images_in_celebA = count_num_files_in_directory(directory)\n",
    "print(\"num images: \", number_of_images_in_celebA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8360056",
   "metadata": {},
   "source": [
    "## Define dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cd9d42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "class CelebADataset(Dataset):\n",
    "    def __init__(self, directory, split='train', split_ratio = 0.8, num_samples=None, transform=None):\n",
    "        self.directory = directory\n",
    "        self.transform = transform\n",
    "        self.image_filenames = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "        \n",
    "        # Split data into train and test\n",
    "        if split == 'train':\n",
    "            self.image_filenames = self.image_filenames[:int(split_ratio * len(self.image_filenames))]\n",
    "        elif split == 'test':\n",
    "            self.image_filenames = self.image_filenames[int(split_ratio * len(self.image_filenames)):]\n",
    "        \n",
    "    def __len__(self):\n",
    "#         return 20000 # if we want to use only a subset of the dataset\n",
    "        return len(self.image_filenames)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.directory, self.image_filenames[idx])\n",
    "        image = Image.open(img_name)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image\n",
    "\n",
    "# Define a transform to preprocess the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    transforms.CenterCrop(64),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Instantiate the dataset\n",
    "celeba_train_dataset = CelebADataset(directory=directory, split='train', split_ratio = 0.8, transform=transform)\n",
    "celeba_test_dataset = CelebADataset(directory=directory, split='test', split_ratio = 0.8, transform=transform)\n",
    "\n",
    "# Create the DataLoader\n",
    "train_dataloader = DataLoader(celeba_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(celeba_test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b57eabd",
   "metadata": {},
   "source": [
    "## Display images using dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98172f8d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnwAAAKQCAYAAAAFa6evAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABU4klEQVR4nO3de7Cud13f/c91uM/rvPZp7fMOOwkBTCOiD4KA1CqQQp3yoJ1KqlY6Q4udjkMcpR1a6JCxFetY29rDjNVOh1qpLTN9fCzyFENgxiYSqgZCSMhpJ/u891p7r73O9+G6ruePaNpNqN9PZEnIj/drhj+y/e7fdd3X6f7eV8znmzVN0wgAAADJyl/oHQAAAMCfLRo+AACAxNHwAQAAJI6GDwAAIHE0fAAAAImj4QMAAEgcDR8AAEDiaPgAAAASR8MHAACQOBo+4JtIlmXW/+65556vaTsf/OAHlWXZn+rv3nPPPbuyD1/Ltv/zf/7PX/dtA8CfpfKF3gEAXz/33nvvdf/8oQ99SJ/61Kd09913X/fnL3vZy76m7fyNv/E39OY3v/lP9Xdf+cpX6t577/2a9wEA8L/Q8AHfRF796ldf98979+5VnufP+fOvtLW1pX6/b2/n8OHDOnz48J9qH2dmZsL9AQA8P/wrXQDX+e7v/m694hWv0Gc+8xm95jWvUb/f14/92I9Jkj760Y/q+77v+7S0tKRer6dbbrlF73vf+7S5uXndGl/tX+keP35cb33rW/Xbv/3beuUrX6ler6eXvvSl+pVf+ZXr6r7av9L90R/9UU1NTemxxx7T7bffrqmpKR05ckR33nmnhsPhdX//zJkzesc73qHp6WnNzc3pne98p+6//35lWaZ/9+/+3fM+Hn/8WT7/+c/rB37gBzQ7O6uFhQW9973v1WQy0SOPPKI3v/nNmp6e1vHjx/XhD3/4ur+/s7OjO++8U7fddtuzf/c7v/M79V//6399zrZWV1f1rne9SwsLC5qamtJf/It/UU888YSyLNMHP/jB62offfRR/dAP/ZD27dunTqejW265Rb/0S790XU1d17rrrrt08803q9fraW5uTrfeeqt+8Rd/8XkfBwAvbrzhA/Ac58+f1x133KGf+qmf0s/8zM8oz5/5bfjoo4/q9ttv10/8xE9oMBjo4Ycf1s/+7M/qs5/97HP+tfBX88ADD+jOO+/U+973Pu3fv1+//Mu/rHe96106efKkXv/61/+Jf3c8Husv/aW/pHe9612688479ZnPfEYf+tCHNDs7q3/wD/6BJGlzc1NvfOMbdeXKFf3sz/6sTp48qd/+7d/WX/krf+VrPiY/+IM/qDvuuEPvfve79d//+3/Xhz/8YY3HY33yk5/Ue97zHv3kT/6kfu3Xfk0//dM/rZMnT+rtb3+7JGk4HOrKlSv6yZ/8SR06dEij0Uif/OQn9fa3v12/+qu/qh/+4R+W9Exz9ra3vU2f+9zn9MEPfvDZf7X91f7V+EMPPaTXvOY1Onr0qH7+539eBw4c0Cc+8Qn9nb/zd7S8vKwPfOADkqQPf/jD+uAHP6j3v//9ev3rX6/xeKyHH35Yq6urX/PxAPAi0wD4pvUjP/IjzWAwuO7P3vCGNzSSmt/5nd/5E/9uXdfNeDxuPv3pTzeSmgceeODZ/9sHPvCB5isfL8eOHWu63W7z1FNPPftn29vbzcLCQvPud7/72T/71Kc+1UhqPvWpT123n5Ka//Sf/tN1a95+++3NzTff/Ow//9Iv/VIjqfn4xz9+Xd273/3uRlLzq7/6q3/iZ/rjbf/Gb/zGcz7Lz//8z19Xe9tttzWSmo997GPP/tl4PG727t3bvP3tb/8/bmMymTTj8bh517ve1Xzrt37rs3/+W7/1W42k5l/9q391Xf0/+kf/qJHUfOADH3j2z970pjc1hw8fbq5du3Zd7d/+23+76Xa7zZUrV5qmaZq3vvWtzW233fYnfmYA3xz4V7oAnmN+fl5//s//+ef8+RNPPKEf+qEf0oEDB1QUhVqtlt7whjdIkr70pS+F69522206evTos//c7XZ100036amnngr/bpZletvb3nbdn916663X/d1Pf/rTmp6efs5bsb/6V/9quH7krW9963X/fMsttyjLMr3lLW959s/KstTJkyef83l+4zd+Q6997Ws1NTWlsizVarX0b//tv73umH3605+W9MybxD9p33d2dvQ7v/M7+st/+S+r3+9rMpk8+7/bb79dOzs7uu+++yRJ3/Ed36EHHnhA73nPe/SJT3xCa2trX/NxAPDiRMMH4DmWlpae82cbGxt63etep9/7vd/TXXfdpXvuuUf333+/Pvaxj0mStre3w3UXFxef82edTsf6u/1+X91u9zl/d2dn59l/XllZ0f79+5/zd7/anz1fCwsL1/1zu93+qvvUbrev26ePfexj+sEf/EEdOnRIH/nIR3Tvvffq/vvv14/92I89Z9/LsnzOdr5y31dWVjSZTPTP//k/V6vVuu5/t99+uyRpeXlZkvR3/+7f1T/5J/9E9913n97ylrdocXFR3/M936PPfe5zX/PxAPDiwv8PH4Dn+GoZenfffbfOnTune+6559m3epK+of7/wRYXF/XZz372OX9+4cKFF2BvnvGRj3xEJ06c0Ec/+tHrjutX/scmi4uLmkwmunLlynVN31fu+/z8vIqi0F/7a39NP/7jP/5Vt3nixAlJz7xxfO9736v3vve9Wl1d1Sc/+Un9vb/39/SmN71Jp0+ffl7/5TWAFzfe8AGw/HGz0ul0rvvzf/Nv/s0LsTtf1Rve8Aatr6/r4x//+HV//uu//usv0B49c9za7fZ1zd6FCxee81/p/nET/dGPfvS6P//Kfe/3+3rjG9+oP/iDP9Ctt96qV73qVc/531d7kzo3N6d3vOMd+vEf/3FduXJFp06d2qVPCODFgDd8ACyvec1rND8/r7/5N/+mPvCBD6jVauk//If/oAceeOCF3rVn/ciP/Ih+4Rd+QXfccYfuuusunTx5Uh//+Mf1iU98QpKe/a+Nv57e+ta36mMf+5je85736B3veIdOnz6tD33oQ1paWtKjjz76bN2b3/xmvfa1r9Wdd96ptbU1fdu3fZvuvfde/ft//++fs++/+Iu/qO/6ru/S6173Ov2tv/W3dPz4ca2vr+uxxx7Tb/7mbz77X0y/7W1v0yte8Qq96lWv0t69e/XUU0/pn/7Tf6pjx47pxhtv/PoeCAAvKBo+AJbFxUX91m/9lu68807dcccdGgwG+v7v/3599KMf1Stf+coXevckSYPBQHfffbd+4id+Qj/1Uz+lLMv0fd/3ffqX//Jf6vbbb9fc3NzXfZ/++l//67p06ZL+9b/+1/qVX/kV3XDDDXrf+96nM2fO6B/+w3/4bF2e5/rN3/xN3XnnnfrH//gfazQa6bWvfa0+8pGP6NWvfvV1+/6yl71Mv//7v68PfehDev/7369Lly5pbm5ON95447P/f3yS9MY3vlH/5b/8F/3yL/+y1tbWdODAAX3v936v/v7f//tqtVpfz8MA4AWWNU3TvNA7AQB/ln7mZ35G73//+/X000//qSeAvFB+7dd+Te985zv1u7/7u3rNa17zQu8OgBcp3vABSMq/+Bf/QpL00pe+VOPxWHfffbf+2T/7Z7rjjju+4Zu9//gf/6POnj2rb/mWb1Ge57rvvvv0cz/3c3r9619Pswfga0LDByAp/X5fv/ALv6BTp05pOBzq6NGj+umf/mm9//3vf6F3LTQ9Pa1f//Vf11133aXNzU0tLS3pR3/0R3XXXXe90LsG4EWOf6ULAACQOGJZAAAAEkfDBwAAkDgaPgAAgMTR8AEAACTO/690m2FcI6nRc2dwPpdTIzVGmfufnDTVxKrLm3FYU092whpJGm2vW3U7G1fjtXY2rLUKxeepqeJB9ZLUKc3zVI/CmlLe8S9y74TmVp23lnMNTSbufnm3VFU563m/x7LCO0+1cTyGk9pbq4lDe8vWlLWWul5dXbbDmk4xsNbq9547euyrGkyHJZU5vaP9VeYTf6XMPOeNeW3vqsb9uvCux29UjaoXehe+JtY3sHEt+qu5de77JXeb8T3QNN7z7MUuywqrjjd8AAAAiaPhAwAASBwNHwAAQOJo+AAAABJHwwcAAJA4Gj4AAIDE0fABAAAkjoYPAAAgcTR8AAAAiXsekzbMqQVGgrebEZ8Z28yreMqDJE22V6269atnw5rN9XgyhiRNRt50jDKPp1D0Ot6p6g06cVHuJZlXVTx1RJLUxMn0pTkNoizMSQPteOpCVXsp65lR17NWkpraS+nPnDEy9tQF73NWxgSBTraLk0IabyKNCu+YDau47sJp794s8gWr7tDLvyOsadrmpJA8TsM3L/9vGv5EiF3d6q6t1LijoPBn4oW5fr5x8XgBAABIHA0fAABA4mj4AAAAEkfDBwAAkDgaPgAAgMTR8AEAACSOhg8AACBxNHwAAACJs4OXazst2Qg6NIJ6JakZbYY1m5eettZau/CkVTcZxsGtRZyfKkmamelbdU5YclF6AZJNK64bmae9yb3fA0XRNdbyLqCxGctdl/Exa8wA1ayJg4srI/RXkgozaDV3AsrNey4rvMLJOA5CzjLvnOdG8HWZtay16toLT68nw7Bmcdbb/1NPeM+NmdUbw5qpvV7wsnM+3Wu2sYK7d9c3S4Rttouf1A3+bYznnh3iTNgw/g94wwcAAJA4Gj4AAIDE0fABAAAkjoYPAAAgcTR8AAAAiaPhAwAASBwNHwAAQOJo+AAAABJHwwcAAJA4f9KGmxheG1MLhtvWWpee+GJYs3X6QWut+dbEqpud7oU1WdubIJCb0yWs4SSFd6pqYyRKt/RGhUyMcylJk1E8KaEwt+mG3BdZPPkiy7xtZorrstxbyxwio6aKj21jTACRJNXmFJA6/n1XFOakDWPSQ2Zes1VpTnQp48/Z6XhTO3ptb982rq6GNVN7jlhreRe3dwM4k1p2n7tNJj08X9Z0D/OwepNC3NFZSAlv+AAAABJHwwcAAJA4Gj4AAIDE0fABAAAkjoYPAAAgcTR8AAAAiaPhAwAASBwNHwAAQOLs4OVxZQYv76yFNWe/+FlrrfWnHwpr5lte6Gyn3bHqyjxer2i1rbVUesesNtJ6GyM0V5KUx9tsNLaWMjN41RiZxFnmhlCb6aKT+DM0tfc5ayO4uCzcEGdv/7MmPh5N5gUvNxMz7bmKw8e9eHJJRVxZGJ9RkprSCzJXFj+uyp53b87Oeudzc/NyWJPVXthzXcb7n8sM295FjRv2bASUp+EbMzjafba8MPu/e6Hiu7tN/O94wwcAAJA4Gj4AAIDE0fABAAAkjoYPAAAgcTR8AAAAiaPhAwAASBwNHwAAQOJo+AAAABJHwwcAAJA4e9JGVm9Ydecf/4OwZvmJ+6219rbj1PlBx0vWzwsvzb8ypl64afjudInCqjMT+LO4h6/H3gSK3JwukRsTFbLanBphTmewUtbNbWbGpI1M5jQLY60/Kgwrqso7T417aRjHrM6934BZO742GmNqjSTl5mNoYkzaqI1JM5LU7lplWl1ZjotGQ2utrBx4G3XWcifS7KJG7r25e16Iz/nin+DwQky9+Eb1Yv+cu3vP8YYPAAAgcTR8AAAAiaPhAwAASBwNHwAAQOJo+AAAABJHwwcAAJA4Gj4AAIDE0fABAAAkjoYPAAAgcfakjbVT8QQNSTr9xf8R1nQm16y18m48RSMrvCTtstP3tlnEPXBuTtBwpy7Uo3hUQlOZUwuMfSt2Ob3bmceRGxNAJD/NvzImctjHzNmmG9huTGp5Zrl4m6U7QsM8nY0xtcCdtFFk8eSa3Lw3m9ybgtMYy2WlN0Kj1e1ZdcOt1bBm+1pcI0nT7fm4qOUei937rZ6Z022azJyW404FMmQvyDuJF/t0BuCr4w0fAABA4mj4AAAAEkfDBwAAkDgaPgAAgMTR8AEAACSOhg8AACBxNHwAAACJo+EDAABInB28/Nh9caCyJI3XV8Oa2ZmOtVauOER1OPRCMjtjr67dMkJDdzFQWZIqI/d0Yq0kFUZYrxU0LKkonEhlqSjjy6iuvGNR115dZuxbbq7V1PHRdUJ/JSlzw5INbtBtZgbF5sZ5are8R4Jznurx2FsrH1p1TRkHsbsh1B0z4HjQjn8TX7l8xlqrt2cprMky755zQrSfKYxLity7znLz2t7d2OLdDYn3ELyMNPGGDwAAIHE0fAAAAImj4QMAAEgcDR8AAEDiaPgAAAASR8MHAACQOBo+AACAxNHwAQAAJI6GDwAAIHH2pI1rFy9bdZ2OkRTfeCn3jeK6ljE9QJLqyptVsbG+HdY069ZSauwJCPHnLIwaScra8TSC2gyvH4+8SQnO0ILKnE7SNN7O5YrXy8zPmRlp/u5gg8q8zhrFUwsmufcBSvMeKIzPkJkjXZpxvG9N7V0/jfk5a+M85dXIWiuvvekeXcV1K+cft9ZaOnEirGm1vAutkjF1RJKM6RiZOccny8xtZvF7BPc+b5xJG+bN6U6kAVLFGz4AAIDE0fABAAAkjoYPAAAgcTR8AAAAiaPhAwAASBwNHwAAQOJo+AAAABJHwwcAAJA4Gj4AAIDE2ZM2Ol0vGX12thvW9KbMzRZxan5tJOFL0s7Q2//MmGjRanmJ86VZV7Q6YU1eGBNMJKmMt5mZkxnMMHxVdZzmX7ujKtzpJFl8PMwBDqon8USIyphYIEnK3Cky8c7VpTmBojDPp/H7LqvMqQUTp86cmtJ40zFkbLNVeNtsmbfTVDve5oVz56y1vvSZT4Y1TX/BWkudaats0Iufx4uzA2ut/t4lq64zmImLjGkckqTcuGaNmmcKvZPuTN5xn1PANxLe8AEAACSOhg8AACBxNHwAAACJo+EDAABIHA0fAABA4mj4AAAAEkfDBwAAkDgaPgAAgMTZwctHDhhhmpLyMg63bLe9PrPdiUOEC2N7z9R528zbcXCu8xklP+BYrXibtblNteLPWRjbk6Ss8jZZ1kZQqZlbXJjhqLVzDZmBrLmxb24I9cQ8ZpkRRN1ueQfNDp41wmLHlbfNkfFBs8o7GH2zrqjWw5q87d1zdeNtszFulYmxX5J07yf/n7Dm/j980lprXHuh7lP9ONR9ad+UtdaNN99i1X3Lbd8a1hy54aS11tyBo2FNMbPXWmvY8q6NlvHgy81QcT9uPq50gtPdrWYyv0/wgnK/d9y5BrzhAwAASBwNHwAAQOJo+AAAABJHwwcAAJA4Gj4AAIDE0fABAAAkjoYPAAAgcTR8AAAAiaPhAwAASJw9aaPT8qKcC2PSQ2mu1TaS0QtzmkXjJlEbUwvcSRuFMbVDkuRMASm8D5A5a2VmSrw5nSRzfjc05m+LzKtryvh45G1vGkFROnXeddbOzOvRKXJGgEh2HHtmTDFx8/fbxq7Vo7G1VrVxzaqbjDfDmswc6VJOvPsptyaieGvNzw3Cmskw/oySdOnSJavuqvGsunzWO2aPPPSgVfc/7vlkWHP06HFrrdte/bqw5tu/5y3WWgvHvOkeTasb1tTmuxL7jYozKsH9EnPme7hLISm84QMAAEgcDR8AAEDiaPgAAAASR8MHAACQOBo+AACAxNHwAQAAJI6GDwAAIHE0fAAAAImzg5fL0gt3LQujrplYa41GVVjTzrxw3U6vZ9VlRsCx3SVX3ud0AjWrsRmuOzaCo41Aa8kPF22McNfKDA3NW15YdZ7H570x00Vro86MQFbmBKhKyov4c2ZePLMyM6xaeXyezExuFcZahXdrSu1pq6zeuBLWjHfWrbXyZmTVlXl8r/TbXlz1nrmpsObGG45Ya11bfdSqK43rrG0GyWeZd8zW1lbDmoe/+AVrrbNnToc1ly7ENZL0/e/8Yatu9vitcVHhfZ/URti5JGXGM8j93iFTGf8nvOEDAABIHA0fAABA4mj4AAAAEkfDBwAAkDgaPgAAgMTR8AEAACSOhg8AACBxNHwAAACJo+EDAABInD1po554UyPi2RhSaU5TqKt4ta3NTW+t2puVULTi8QCttrf/5tACcy1z6oIzKaTb9TZauCnx8TErS+9Sa8zzVI3j1H/3nOfOcBhjYoEk1eZJb4wpLJ1Wx1qrMM65JMmZAmJOCrE+pjGNQ5LyrjeSo1fE19Cm8wCStL152arLjcNRmPfm3CA+nyeO7LPWWl5eterW17fDmk7bO/7d/sCqq6txWJNX3jErqvg+f/hz/8Naa77nvd94ww+8K6yZO3iDtVZdesesMiYHZc7FKCZtpMSd3OTiDR8AAEDiaPgAAAASR8MHAACQOBo+AACAxNHwAQAAJI6GDwAAIHE0fAAAAImj4QMAAEgcDR8AAEDi7Ekbqr3U/Ekcsq6JO7XDmEbQmEnUZe5F8BeFsW+VOY3AnPTgrNYypgxI3kSOzN2vxkvDdyZaNO7UBXMiR9mLpxY03sdUY1watVMkKTenY9S58VvLPP5NZU5EMc5Bk7m/AeOrNsvNiTSNd85zY8LNYHbeWmtnsuPVDeNJPp2eN7lmphc/W2anvGN2/PiiVXd5ZTWsKcx7c2Dcc5JUVcaNV5nX2SReqzLP5efvv9eq683E0zFee/sPWGv193kTOdSeDUsauROejHvTWgmp4Q0fAABA4mj4AAAAEkfDBwAAkDgaPgAAgMTR8AEAACSOhg8AACBxNHwAAACJo+EDAABInB28XHm5s8rzONJxYi42MQJ9Ox0vDHQy8bZZTuL9z3cxkFiSciM8ujLXarJ436raSMeWlOfm5WEEtxZmIHFRmcdW8fGoW+b+N3GgadHxfhvVjRcq7uQ4N+bvsSbzgnObOl4vK8y1jG2611nWeNeGjG3mHe+cd2fnrLrh5lpYU7R71lqtcius6fW84z8307bqxlV8bAsz1L1r3sPtwghFN+45SarH8X0+2omPqySNhutW3RfvuzusKUrvPL3qe/9vq25q6aawpsmnrLUq4z4pzOhlP6DZe257K+1eLDQB09fjDR8AAEDiaPgAAAASR8MHAACQOBo+AACAxNHwAQAAJI6GDwAAIHE0fAAAAImj4QMAAEgcDR8AAEDi7Ekbk8qb9DAejuKNmmn+WRb3o+OROdmg8XrbHcX7v2OtJJWld3idaSH1xPucmeK6xjxmWe6l4RetbljjJOZLUmOm+WsUH9u8611neS/OY6/lTWqpxl5dqxcfs2biTlcxU/Nb8T0wybxt1nmcrJ813n7lY++Oqp2JEJl3z2V9b2pBf9+xsGZjbdNaa2flUljTaXv7P9fvW3Wj7XjaiXVcJfXM6RLdVvzcaBvPDElqjKlG21ves92tG+1shDUP/v5nrbU6He88ffsb4mPW2XfSWmu7MwhrSnMGRcu4zyUpNyYMuRM0nEkhz4jXsxucbxK84QMAAEgcDR8AAEDiaPgAAAASR8MHAACQOBo+AACAxNHwAQAAJI6GDwAAIHE0fAAAAImj4QMAAEicHURd1V76tTNdYjLxphE4isJMTx95ieG14kkDtTl1RJk30aKexJ8hNz9nXRkTEOzT7h2zbsfZpjndo/TS2FUO45qxUSMpr+LU/8ycgNDttq26ypgukZXeNIKs9rZZj+NzULS96Sp5GV+P2S4m5kvec6PJvfskM7fZmZ4JaxaPn7DWWrl8PqzprnrX7HwZTwSSpJ3WVlizaU6R6XW8a2OmH1+37hSi2njUlrn3PG4V3hSfcSt+nm2Zx+yRB/+nVTfVnwtrXv6GaWutvLVkFPWstWRMOpEkmdN+dtPXf4svfrzhAwAASBwNHwAAQOJo+AAAABJHwwcAAJA4Gj4AAIDE0fABAAAkjoYPAAAgcTR8AAAAibODl6fnzNDKURwI2mq8PnNorJW7QauZV1dm8ecca2ytVRlBt5K0ur0e1jRmAGZmBDRPJt7+d1re5bHRXIvXMoNWu20vRLjVidcbmWGgrX58zltmoHLR9cJpW624rmp54a7ZyLvOWkZwbj32rg0noLl2f08a95xk3utm2HNtxrY2RXzfteZmrbUO3vKKsObU5c9aaxX1qlXXN45Zk3vX2aDrHdvpfnxv5rn3PMiMe7jb8q6zzcz7nGPjY7bMUP0m8wKyn3zoc2HN3NIBa63Dr3xtWJN1vHPZmPewU+eulZv3JsHLzx9v+AAAABJHwwcAAJA4Gj4AAIDE0fABAAAkjoYPAAAgcTR8AAAAiaPhAwAASBwNHwAAQOJo+AAAABJnT9oYzJjJ3HWcmr+9veOtlddxTeOlpzeVl8tdV3EPXJhp/pW5bxNjIkfTxMdCkppxvM3heNtaa3PD2//cmAKSeYNCVJgTUYo8nnzRbnettdrd+DboGtM4JKnbcyeFxOsVXe88FcZakpQbkzbynreWjEkbWe7dJyq9aQR5Kz62jbz7xFnLlZXeNTt7IJ6UcPClN1lrPbK8YtXVm/E5yMzJO94MGSk3zkGn5V0bZRFvtZB3/WT9nlU3KeN7oGNOW3K/n8om/k688PiD1lr7b3xJWNNuz1hrVeZZb5zvRPs7wJwqtYtV3yx4wwcAAJA4Gj4AAIDE0fABAAAkjoYPAAAgcTR8AAAAiaPhAwAASBwNHwAAQOJo+AAAABJnBy+32lNWnRMi3B94gbh1sxHWXLu25q01ifdLkvqt+JAUudcnm3ms6hqBuHXtBXhub8d1O1teOO3mpheQvbkZBwQPx942JxMzqNT4rdIxwoElaXoqDmSdmvKu2UHfq+t04utsYN4nLfNzdqcHYU170LfWKo3PWRj30jMb9UKQq5YRHK1pa6089z5nU8ehvnlh7n8eB8ounjxirTV17rRVd/5qHNCcG2HtktTKvOusbYQl981QdOedRKvn7Vcn90LFJ8ZyVel9n1RmyH1mDAaoNq5aa127EF8be+aPWWs1hTlkwAg4zs1QfTuhGc8bb/gAAAASR8MHAACQOBo+AACAxNHwAQAAJI6GDwAAIHE0fAAAAImj4QMAAEgcDR8AAEDiaPgAAAASZ0/aGO14vWGTx1MLLl9cttZavhDX9bpeyrob8j1u4ukSI7NPbsyNrm9thTVrG+vWWmvX4v2/dtVLf7+y6k0x2dwahjWra/HUFEna3o4nG0hSPYknd7SKOP1dkga9+DaYmY6va0nau2feqttj1C1Oebdnt+dNEOgZkzv6s94EiqmZeKJFz5za0ep5xzbvx3UTeRMQ6sqbIpN342NbjbxpBEUZH4+q5a119OUvs+ounrkY1lx9wpvakeXe9Zgb0xly897stuLjPx6Z03m63kSUiVNWeNMgqpH3/VQZk6Aa79LQxuVzYc3sce/ZXk6ZE2mMmmy3B2h4lxD+N7zhAwAASBwNHwAAQOJo+AAAABJHwwcAAJA4Gj4AAIDE0fABAAAkjoYPAAAgcTR8AAAAiaPhAwAASJw9aWN15bJVNy7jZPEHHnzQWuvCo0+GNceOH7TWOnHLCavuyvq1sGZjy0vz3xp50eI7VZwUX5kx5WV3ENbMLHnTIMoZr25rO55asGCm4VdVPEFDkupJfJ3VY29qx/bGSlizteVNOnnw0aesuvGXHg9rFnreZID5uRmrbnHPXLzNRW+t2fl40sb8bFwjSfsXFq26/uxUWJNPeRM0smmvrunH56AwpkFIUp3H12OWeVNH+r34WEjSy297ZVjz2eVVa62xOV1CZfweoWte2y1jk2XHW2vsPbZVtOIRDpk55mGceXVD59owp5PUW6thzWjtkrVWOdhv1eVNfM6Lxrx+zGNWG8vlTOO4Dm/4AAAAEkfDBwAAkDgaPgAAgMTR8AEAACSOhg8AACBxNHwAAACJo+EDAABIHA0fAABA4uzg5asXLlp1O0bS4R4jQFWS5m85GdbkncJa65IRqCxJy1fiurrytnn0yEusun374nDLra0Na63tre2wZjzywo3Hs15Y8rYRvDwceiHIMrM55/rdsKZrXt3dMj5Pw5G3/1eurVl1K1fj83npXBwILUnnzHvzS4+fD2uy0ru2Z+bmwppDB/Zaa53Y64U9H1iK19u73wtxnlnoW3VT03Fda9oLSy6m41D0rOXdc3XjnacDh/aFNS/5lpdZay2f8ULFW13j+W7uf8cIVR5XZih9Lw5rl6TG+A4rzXDgSct7pzIcx8ejMe/NlhHSP9m46q0lL626aeLvFDcD2fwKsAOa8b/whg8AACBxNHwAAACJo+EDAABIHA0fAABA4mj4AAAAEkfDBwAAkDgaPgAAgMTR8AEAACSOhg8AACBx9qSN5RUvmXtjMgxrxubUgkHZCWsuLa9aa5V75qy6+X1LYc3S3kPWWgtTXup/tRMfs2zk5Y93izhNPiu847++6k2N2NrcCmsKY78kaWbam7ow24knEswP4pR+SZqbmQ5rGvO3UZ0d9eryeN+ubXnn6fTZeIKGJD36xKmw5olTp621zl64FNacOedNAHmo4x3bxcXZsObIwXiyhCQdXFqw6o4dORCvZdRI0vRifG1nvXhSjiSVg/hYSNKkjqcznLjpBmutLXNaUceYgtPveM8DZ1BFWXgTKBqzTsawk7zxJlB02/F3mCS1xvHUiFHj3SdtY5t55e2/xmOrLGsb30/uYAx7gAaTNp4v3vABAAAkjoYPAAAgcTR8AAAAiaPhAwAASBwNHwAAQOJo+AAAABJHwwcAAJA4Gj4AAIDE0fABAAAkzp60cWkjnqYgSWvb62FNte2lyR87cDCsWTQmY0jSkVtfZtXNzMyFNdXQm3ox2tmx6rJxnHpeZrW11vZOfJ5Wr3pTU7Y3N606Vd7xcNTjeOqIJMk4Hr2ZnrVUr4xvg7z0pnaoFU8ZkKS6jOu6c/EEEEla3D9v1Z244UhYc+aMN7Xjy488FtaceuqMtdaFyytW3VNnL4c1T5+7YK01Pe2dp6WleHLHLTcdt9Y6eiRea+9Bc2rHgvc8HkzF10a/8KZBLB3ynrUbK/F5mkzMqREt4yvKnOJTFd7XXa74eVbV3vO4aHnTIErrHOzeM6gy16rcFqGJP2eeud8T3rH1Jm0wjeN/xxs+AACAxNHwAQAAJI6GDwAAIHE0fAAAAImj4QMAAEgcDR8AAEDiaPgAAAASR8MHAACQODt4+cmVVW9BIwPz4J695lpxcO7Nt77KW2thxqq7eikObu0a+yVJmngBkqURSDmaeCHOQyN4OWvc/bLKVBl17dL7bdFte5fkzKAf1vTbXnBxqzDOZ+7t/6jyju0ki8O2JxMvHHW4Pbbqyir+DEcW4nBgSZq/JQ53Pbn3kLXW0+eXrbpzF+NQ6DNGjSQtX/PCnq9cOx3WnHra2+YxI3j5JSe8Y3bieByiLUmHDx8Na2Zn91hrLe6ZterWr8bP0C3jOSVJRR3f51lu3idmQHzXCFnPC2+tiUZWXdOKt9npesd/u4nvzay3YK01yrxQ7swIXi6bylrLDl7OnC+owtzmNwfe8AEAACSOhg8AACBxNHwAAACJo+EDAABIHA0fAABA4mj4AAAAEkfDBwAAkDgaPgAAgMTR8AEAACTOnrSxVXvJ4iePHA9r5rpeMnqzGaeUn37iSWut8WlzgsNUnOw+NR8nmUtS0fb66eHWelizsR3XSNLmZlyXZ97x73TiYyFJtTFdYsE4rpK0OONNMVmcGoQ1ZeGlrGeKx8M0jTFCRtLamnee1oZxXafvTYcpzUkDWRV/hmsrV6y1nnj88bBmfWPTWqtsx+dSko4dWgprpme8Y3FhxdvmhaurYc36uvc5v/RoPJHjybPeBJAjj3jTPW658WpYc+iGeBqHJC0cO2DVTU/FEyFGy/E0Dkkat+LndpZ5EygWD99k1fUH8RSK8XjNWmvj6jmrLq/jyTsyn8fDOn7uLcwvWmu1GrNFMIZj1LnXQ9Ty6nJncIe3lPXqyxgm8kd13kYbY+dyc6OZNXWEN3wAAADJo+EDAABIHA0fAABA4mj4AAAAEkfDBwAAkDgaPgAAgMTR8AEAACSOhg8AACBxdvDyy2+40arbd2BPWNOajK21hltxCOnFc2ettRaPHLHqOmUcTlvkXsjheDi06oajuG409o5ZYey/aq/Pb2on2VJamI2DTw8teuGosz0v4Lgs4s+Qub9nsrhuOPKOxdr6jlXXM45Zt+8ds62tOKBckq5ci8OeV7a962zSi0Ng19a9EOqty5e8bY7i9aanvOvnxOH9Vl2vG4esXyxXrbWubG2FNRtjI4BX0h8+dMaqe+iROPj30E3HrbW+601vtOpuPhof26zwwutHTZzo26696//qined7XTiUO6p2XlrrW7jhfCOLyyHNTtr3vfJ1J44VLldePtVVN42HXXjPVsaM0S4No6tmZVs11lruWHP1kZ3dTHe8AEAAKSOhg8AACBxNHwAAACJo+EDAABIHA0fAABA4mj4AAAAEkfDBwAAkDgaPgAAgMTR8AEAACTOnrRx076DVt3Cvjjle301ThWXpMuKJ210Ox1rrW63bdVlRVxTmxMostzrp8dGuv5kEifOu2vVlZfm32t7afj7F+fCmtmZOL1ektrmT5DGSVk3JmhIUqX4fE7MJPPWYMqq2xjF5/PUBW+awuOnvLonno7rVq5dtdaqFV9DC3Mz1lpH93tTL7JJPN2jn3vX9uGD3vNsph2fz2xsTlMwfl8vL1+z1lofeY/uoogfaO14AIgk6SW3vcGqa+XGRIXCe25no/h4DMxn+9XLT1t1o7PxRI7W0cPWWlNz3rSc/lw8uWN94n3vbBmXxsqZx6y1ugNv0kZ3Jt7/vPGex0XL+96pjfalys2JIsZ0j8yceuFO2siaeJtGyfPCGz4AAIDE0fABAAAkjoYPAAAgcTR8AAAAiaPhAwAASBwNHwAAQOJo+AAAABJHwwcAAJA4Gj4AAIDE2ZM2Vs+cs+q6vTjZ/fTTp6y1yiqeRjA95U1wmJmKU/olqT8wUr6NKQ+StL3tRdhfu7Ye1lQTb5vrG9thTcucALJ/IU5Pl6T56V5Y0y6NESaScvPYNkUcQe5MGZCkqo7X2toZWWtdMY6/JD1xNp428/kHn7DWetSYoCFJq9s7Yc3W2EvWL4r4PM2trllrtUvverzp6L6w5sZDe621lsxre7Yfn6eV1fj+laQnrsZ1a8YEFknakjddomjiR3x3zpt0sv/ozV6dMXln25x6sXzqobBm1MTXtSTtP+hNvdCZeNrMxlnvnptsb1p1M4vxhKrBvDfFp9tvxUUTb4TDxmY8dUSSVtcvhjUdZ78kTfW8e7M9eyisqTtef5Ap/q4ozGlLMic8OYM7dnnQBm/4AAAAUkfDBwAAkDgaPgAAgMTR8AEAACSOhg8AACBxNHwAAACJo+EDAABIHA0fAABA4uzg5fW1a1bd5FwcFbi67q21dzAd1nRaXphjt3Q/ahx8OhyNrZVGQy+sNzPiFTc2vADPqqrCmq55zFrmz4G2EYLcyr0Iybrx6prMqDODl8tOXNctvGO2cd67tv/woUfDms994UvWWle2vbDk7mwcPLv/2HFrrRsOx6GnD3/+f1prXbp6xaq79WUnwppDxw5bay0MvCD2xrg3e096IcJnl+PPec4IZ5ak8cQLXnbuzdVNLyB77cqKVXdw/1JYM33wJmut1mwctr155YK11qT2QtHLpTgRt2M+G9eNcy5JG5fjusUt7z4f7J8LawozeLzsGYMIJHXH8bEd76xaay0/7oVazx6Kv6sHR05aa2WZk4Ls9hDm8AAnVtkcRJA534fiDR8AAEDyaPgAAAASR8MHAACQOBo+AACAxNHwAQAAJI6GDwAAIHE0fAAAAImj4QMAAEgcDR8AAEDi7EkbWdebNDCYi6djNK14GoQktSZxkrY5wEHVxJt6UWS9sGZn20tsn1QTq257K16vjg/FM4xJFZ22l9I/6Hasurwxdq7xznmee5dkZtRlpfd7JmvHa/W78XUhSSdO3mjVHTp1Oax58qKX0n94fsGqmxjTQl55223WWt/7Xa8Ja+7+b/FkD0k6d+bLVt3Cvj1hTX92ylorN8fIDBbj59nsPvP4Gw+rsu9dZ3sW4kknkrR2+WJYs3z5vLXWFz53r1V340vieyAfzFlrZbODsGZm/qC1VtF4z+O6js9TZkxkkqSFQztWXWtzNaxZPf+4tdbljXgiyqI5mWFqdtGqm56Kn6FD80tsY9Ob6HL+y18Ma44txlNfJKnox8+NJjcnaLg9iXEN5ebUjkLeVCne8AEAACSOhg8AACBxNHwAAACJo+EDAABIHA0fAABA4mj4AAAAEkfDBwAAkDgaPgAAgMTR8AEAACTOnrSxUXop2TcMZsKaan3T22gTT8fIul4StQovZb3ZiSdCjLe8qR1bxgQNSRoO430bDsfWWt0iTtwelN5pb+feRI5qEkeL52aye2aOTmkK43pseZ+zcepyL8l872LXqnvbd78qrJnKvd9jyxtemv+2MexkwZwg8Pj994U1UyPv+n/VjTdZdcf27A1rusbUFEnKM+950O/H673k8H5rrVccjlP/s8tb1lp7jh+z6s5k8XPj6EI8TUSSZjve86AwJhLk5tSLxviKyhpzoo68aVGl8Qzq1t7kILW8ySnZbHxs98zEk2YkaWfjWlhTn/Gmdmyf9qawNAfia2jbnKI0mPLO07WzT4c1V856n/PgiW+Ji0rvOyArvJ6kzIZxkTH15RlM2gAAAIBo+AAAAJJHwwcAAJA4Gj4AAIDE0fABAAAkjoYPAAAgcTR8AAAAiaPhAwAASJwdvDw2Q2DzdhwgubnthYu2yzjAcGrWCz3NCm//GyMzMc+8tYZm8LKqOIS0bQQqS1LfCBHumSHCZe0FSNY7cbhrVXmBvtnEC2TNmzicMzM/Z24EZdZmIHFphM5K0p49cUD593z3t1trPfLkaavu6fMXwprVy09aa11cvRLWHJibtdY6sveAVbc4Mwhr3F+wdWMGgRfxdXZgjxeI+8qbToY159YetNZaW/YCcTMj4PjEDV6I8/z8nFU32omfe72eF/ZcOt875vO4abx72AmJt7843SvS2GY19sL3+4P4vpvsOWitdfazD1t1+4yA7/aeKWutqusd3blBXLf29KPWWgcOn4iL2l6ofiPv2VIageGNeW1733S84QMAAEgeDR8AAEDiaPgAAAASR8MHAACQOBo+AACAxNHwAQAAJI6GDwAAIHE0fAAAAImj4QMAAEicHRh+fiVO1pek1c2NsGZz6E2gaLV6Yc1gOp5YIEkTbwCCRptxMv3YTDx30687Rpp8px0n/kvSoIxPad+cQNGaeMn0zfZOWDMZWktJ5kSUfBR/znzonafSGO7RdLwLKIsHzUiSCmNyyt498fUvSYNpb1LCzTfHU2m21uP7V5LGG5thTSfzrrOZqXiChiR12vG1kZm/YRtzcpAzkGMw6Ftr3XryeFjzxVPe1JTPn75o1eXGFJ9hFd+/ktTqeBf31mZ8bXRnzWdLFt93ee5NNnAnJEnxNt0pPjKne2TGeapG3nmSMW0pm5mzlhrMLVh12xcvhzWL5gQN9b2JFvVUfD3uLK9Ya21cfiqs6fXM/TK/BDLj0rDfyJmFvOEDAABIHA0fAABA4mj4AAAAEkfDBwAAkDgaPgAAgMTR8AEAACSOhg8AACBxNHwAAACJs4OX1ze8sGQZgZSFGa6bGaGbMkJzJSk3gzKrxgjArL0wzdHQC8qc68fBrYNWx1qrbOJj1jOCOSVJRhioJKmOg09rI8xUkp1WXVVxEHUxNrdppHIXfTMotudtszHOgZvt2m95+9ZrxQuOSy9ctOob15B5+NstL1Q8L+LrzL3PJ2YgbmM8D0pv93X4wFxY8+qXn7TWKtteuOsTl+JA3M31a9Za6xvrVl1jPIOqyjv+RemFKu8uZ9/c/TLfqRj3ynhjzVqqMzUV1mRt7/tket9eq+70E18Ma/o975rtLU1bdZ1BHEw/a4SAS9K5L/1+WLNkPH8kqT09b9UNjWuoNfGun2LfCauON3wAAACJo+EDAABIHA0fAABA4mj4AAAAEkfDBwAAkDgaPgAAgMTR8AEAACSOhg8AACBxNHwAAACJsydtvPH1f8GqW9q3ENbkG1ettcabRrL7yEtsz800/0lVhTXbW1vWWuagBC1Mx8ni7dobW1DmcQ/f63jTFNxfA40xeaSx0uuluvI+p3M4zGEKkrHNLL4snjHxppNk3Th1vjanKeS5OdKiHoclhbn/uZESn5kjKPKOV5eV8R1lDHmQJJW5l5o/mcTHrJl4af7dTrxzLzniTTZYWfOmXlxbXw1rMnOiznDbmxzkqMzrrPAGQuwq68rIvKejeTlaz1p30oaG8VSs1rx3nbX73r15bWcjrFl78CFrrVsXXm3Vlf2ZsGYw552ntbPxRJqNh+JpHJK09+Rxq27cjfdtfW1ordVh0gYAAAAkGj4AAIDk0fABAAAkjoYPAAAgcTR8AAAAiaPhAwAASBwNHwAAQOJo+AAAABJHwwcAAJA4e9LGvsVFq64ajYyaOL1ekppxPN6g2/KmEYwzb+6Fk7JeVeb+mwn2s1P9eK0dL3F7ajAVF5nx74UxQUOSmrExjSDzJhvU5niM2vkQ5v7nxv5X5mQGs0y5cTyaxpzV4k7aMI5t0XgfICvi+64pvMdLbR40Z7pKVnnnvNqJpxFI0ngST9Upjek8kpRn8QfYOzuw1jo4b9znkp7qxaMq1sxj5o6uqev4eEyMe06SWsZJN4de7CrzNrcra+NzDre9iS6T9fi7ohz0rLXaU96ok5l9cX9w3//3GWutG7/tz1l1C3uWwpo89yaF7NuJr8cLp09ba20NvOfx3A2Hwpr+zO5e3LzhAwAASBwNHwAAQOJo+AAAABJHwwcAAJA4Gj4AAIDE0fABAAAkjoYPAAAgcTR8AAAAibODl7PaCyrd3FyPN2omZVZGaGUtLwx0c2vNqmuVcVDjoBcHJT/DC90sW3HAbjX2whyL0jhmXk6sl3QrKSucz2kG+tZmwLFx3jPz2qiM67E2w3XLsRe2nWVx0Ger9u6TrPTqmjy+zhrrXEp5GT86GnO/3Ossr+JQ98nWjrVWZQb/Nnn8GbLSex4URhB1t/D2a67vhXL3O3Hd8rp3bQ+HXvj7ZGzUNd59YoU9m9ePm9DshMTn8o5ZZe6ac9brwlts0I6PbV7G39OSlJnh9Yf2Hwxrjh/aZ61VGPe5JGWFcT77XW+tuTiIerb29v/iuYtWnZr4edBve/tfHvE2yRs+AACAxNHwAQAAJI6GDwAAIHE0fAAAAImj4QMAAEgcDR8AAEDiaPgAAAASR8MHAACQOBo+AACAxNmTNg4sHbDqNpfjHrIYbllr7WzEaeDjiZfYPjEnJWRZnEw/NT1trdUZDKy6za14iknb7M13RnFKeWF8Rul5TJfI42T6wpjyIEnmcAkrgD8zEvMlKTP2v/GWUt14x2wyMbL1zf0vs3g6jOR9ztycRuBMMWnGXkp/M/KmS9TG2IJmx0zplze1oCzi63Zn23ueybiftobe82zbO2QaGZdjZT5D68qrG4/iSRu1cwNLyjLnPJnjLOy63ZObE4ZaefxV3JF5nxvXULaxYa3VVN50lb5xnxw+sGStlZvfO5Pt+HuzNvZLkrqdTlgz2LvHWmu45j0PHn3gi2HNgZkFa63j32mV8YYPAAAgdTR8AAAAiaPhAwAASBwNHwAAQOJo+AAAABJHwwcAAJA4Gj4AAIDE0fABAAAkjoYPAAAgcfakjf7UlFW3uXLZWKtvrbVSxP3ocOwl67c7bauuMgLg+92etVY29uLwndT/oTlBoKrjurZxXCUpr700/CKPE+AzM/G8MKdLNJN433J30kZhTNowE/NddR2n4U9qc//NMSCl8fsuMz+nc/ybsZeYX3gDHORMStg2p16MzekeFy5eCGvWVuOJQJLUn4on9DTtrrXWk+evWHXXNuNJCbkxgUWSxmNv6kLZiu91dyJNY0zkyK1pHJLMOqfKndRij+hp4nszNydtbFyMr422e/wL7zugcu47d6KL+b1Zj+P1nOtHksrGOJ9Ds9cwv3cunj4d1mx3V621jltVvOEDAABIHg0fAABA4mj4AAAAEkfDBwAAkDgaPgAAgMTR8AEAACSOhg8AACBxNHwAAACJs4OXt7e3rbrlKythzb4pL7i4aMW7t7G5aa01NTdv1TkZpGXLC8CsjHBaSWq141Do7bEX9Lk93Alrso532kszeFm5ERpaesHLjRlo6qxWGPslSZlR12Tu/pvBxUZNZv8c845Z5oSQGgGwkqQ6Dm5tzKDVIvdC0Zsyvm5rI/RXklZWveDiznQcOH9ica+11qlT58KaB774hLXWkyurVt2W8dwoOt45b2ovELfVjs+BmfVs3QNmzq0k83nmsHOXvZ2rjQ+aT89Yay1fia/tXu0FlPdmOlZdbgTJb2ysWWu1rnr3Znf/nrAmMy+0kdFHbF29aq11/kwcqCxJO8P4HGwb4dLPB2/4AAAAEkfDBwAAkDgaPgAAgMTR8AEAACSOhg8AACBxNHwAAACJo+EDAABIHA0fAABA4mj4AAAAEmdP2hhVXuJz3cQR5O2Ol95dto2JFmbL6k5waBtTLzqFN2ljdcNLM3/s8VNhzbY5UWTP3HRYU+bepJM896YWVM7UBfNSc6arSGa6vpmG76zlT70wJ204Gy3cEQLeB62N81RMzINmTGFxU+6rwpyIYkxwmFqK0/clqb13zqormvgzXPjyU9Zaly7GU4i+8LA3aWPc86YuVHl8zgdt7zxtb3vPs4kxYaUyv0+8a9u8Zk2ZtZy3zcq8hUfGLdCaiae+SFLWjb9fa/NcVu34+pGkponP58zirLeW+6wdG/tmTqrYurYa1lw4e9Za6/yFeKKOJOXGd93IO/w23vABAAAkjoYPAAAgcTR8AAAAiaPhAwAASBwNHwAAQOJo+AAAABJHwwcAAJA4Gj4AAIDE2cHL20YwoSRND/phzaT2whCrJg53Lcxw4J4RqCxJuRGI6wbKbg6HVt2p8+fDmo21DWutJj8Y1vS6XnB00fZ+D0yMEF43+LqwEpUllfGlW1dmaqVxPvPc/G1kXhuZ8VvLCmd+ptKqqq3z5Mmc+y73Hi910fXqSmObLe950Oma1/bWdliTt7z76eaXvzys+fzZK9ZaZze8Z8vYCRXveM/G8Xhs1dWTuM69zhojyLwx31u4d5MU3yfuau4bldxJezYHFjTTccDx2qXL1lqtgTmwoBeH+U/v3WetVfa8z5kb/YGX0O997zfO9iS1zF6jm8fPjdy7zW284QMAAEgcDR8AAEDiaPgAAAASR8MHAACQOBo+AACAxNHwAQAAJI6GDwAAIHE0fAAAAImj4QMAAEicPWnj7BOPW3VHDi+FNXlppl/v4jSFemRO98jiNO2s46X5zy0uWHXHT94Y1qyurltrTeo4mnvTTMzvdbwJCM7UhdyciFLYkyri9erGzNY3UtZrM2U9b7zfUNbhMHffncjRGNNCnBpJkjH1IsvMc16ax8zYZrW7A1FUD0dhzXgc10jSYDqeRnD86AFrrauPnbLqKuNe73bi6UiS1CrMg2vcKu22OTUiM65Zd9KGO97DmQPiTnAwb+KW4u+xuvC+rsvpxbBmsnLKWiurvO/Nwnhu9Ofj/ZKkuvK+n5o6PmZ5y5yw5UzLMZ+NLXPyjjN9qm2u5eINHwAAQOJo+AAAABJHwwcAAJA4Gj4AAIDE0fABAAAkjoYPAAAgcTR8AAAAiaPhAwAASBwNHwAAQOLsSRuDwcCqmxjJ7tODKWutdjtOmc6MJHbJS+mXpIkRsu4GtudmnP/i4lxYMx556ePDzTj1v6q8qRFV7dU1zjEzD5q5STlDNDIzDb90JrqYO+Zu0xqjYU4KsTe5i5ramUbgTaDI6x2vTvGkiqby7vPttXgijSRdPnMhrDl35oy11sZ2vM21jSvWWt22d0PVxuOxX3hrtQvv2Dr3gDt5x7+fdo8zucad7uGOy8mM9Qpzis+gFU9OyTvT1lrt0pwwZHzOTsebejExvwNKZz1vUIiaKr4HjMEekqTMna7SNtov85y7eMMHAACQOBo+AACAxNHwAQAAJI6GDwAAIHE0fAAAAImj4QMAAEgcDR8AAEDiaPgAAAASZwcvz87MWnWFEeKZ516f2W7HwYqNk5QsqSi8j9oYQc6Zuf9u8HK7FYeQdtveNkeb8fGYjM3gZfPYVkZopRv27F4bmXE6nUDl3eYGNDdGEnXufEh5oa2SlGXxNp39kqR6EqeQNmZSabXh1S2fvhrWnDpz0VprdXndqhtdi0Oht4ZmiPPORlizbYa2bssMki/isGq1vRBe5eYz1LiGCjMIfzfZ4e+7mfVsbtO5hzPzeTA1NRfWXK3McynveTba2gprKuNSlKSs9J5nTW2kKpvBy+OtOCR+vOMtVhvfh5KUd+ILrTT7Fhdv+AAAABJHwwcAAJA4Gj4AAIDE0fABAAAkjoYPAAAgcTR8AAAAiaPhAwAASBwNHwAAQOJo+AAAABJnxzhPKi9lutOJp2NU5lrOpI2dUZyEL/kTHDaNxPCZ6Xi/JKnVbll1g04nrNlav2attb0Wf87RyDv+o9HYqzMmWoxb5tSI3Evgd4Zo5NnuRea71487qcJK4DendmTu5zS22ZgTUUajOJn+9NPnrbUee+S0VXd2+UpYU/a8qRFF7d3DV8/H2zxz7py11priiRzdxXlrrarr3U/lIB5vYB+zlnfMnOvxhZiC494meRPf6405EWU31eajpTM1E9ZcWvO+N6u1Fauu1WyHNf3FPdZagxnvehwP488wGXpTfDbX4ik4ox3v+1DmtZHl8QlttXb3OuMNHwAAQOJo+AAAABJHwwcAAJA4Gj4AAIDE0fABAAAkjoYPAAAgcTR8AAAAiaPhAwAASBwNHwAAQOLsuPPGjPnu9/thzXi4aa3lTDfYMdK2JWlnFKfcS9K4ipO5q9pL724mXjL3wsJiWLNvb1wjSddWroY1O2txKrok7ex4x2zHOE9l7iWG54WZUm7WWWtl8f7bKf3mRI7KuM7caP3a3Lksi6doWPslabgdXxvVxJva0enFzwxJuuml+8KavOOtNdz0ru3MmDYz3T1mrbVn/96w5unVi9Zaj10+a9V1+/H12C288yTzuVcU8bQcdzpM7UyuycwRFOb7jcy479znQe0OwTGeQY35DC2npsKaURlPd5KkU09503Lm2/H0pnIjnmIlSfsPxPe55E1SWl/3eo0NY/LIZOxd/7l5nhrF9525lI03fAAAAImj4QMAAEgcDR8AAEDiaPgAAAASR8MHAACQOBo+AACAxNHwAQAAJI6GDwAAIHF28PL0YNqq6xvBp1tmIHGvHwdITpo4aFiS8qJl1bWdENI8DhaVpO3aC3ddN0Khu1MDa62eUXf16rq1lsygTBm5p4280MqyZYZblvH1mGXe5e3UZWagsrI4gFSSKiN0U/LWymszUNY4B0Y2syRputcNa7pHlry1pmasuu7UQljTGcxZa1Wb3rW9PBt/zvqadz/NzMbh6a0z1lJ68pIXvJw1cXJrbqYDl+2et812/B3Q5PFx/aPF4hrjM/5RoVe2i2m37kpOkHOVe8+zvB2HKu855N2bj571gsynuvEzaPXqsrXWhYuXrbp+L74e/TMZ739tBny74ftFZgSUV26ouIc3fAAAAImj4QMAAEgcDR8AAEDiaPgAAAASR8MHAACQOBo+AACAxNHwAQAAJI6GDwAAIHE0fAAAAImzJ230+96kh8YIhi5Kb7O9XpzyXRbuNAWvt22V8USO3Jy0UTkHQ9Lq2lpYU1beCIS5xXgawdratrXWynkv8Xw8iienTCZesn4tbwrLHiN1vudOoMjjY1ua12xeeucpN1L/KzPxv67N8RiVM7nDu7ZL49BWZjJ9Zk4UeezRR8KaVsub2rEwM2vVbQ3jKThr6/H9K0nrRmr+ysaGtVZmTFOQpI4xjcAdIlO2vHugcp5V5nSMxqlzxlRIkjXd5vmsZyy1i5WZuV+1MTlo3/GT1lpf/sP7rLpJvRnWzE57UzsuXIzXkqTLK/GUrRl3QpUxOah0J2g4D0dJRRHXlbs49UXiDR8AAEDyaPgAAAASR8MHAACQOBo+AACAxNHwAQAAJI6GDwAAIHE0fAAAAImj4QMAAEicHbw8HMUBpJJUtuJA0E7HCw2tCiME1gydbczg4uE4Dv5tVd7+t41wYEnqd+P1VleWrbVK45QePnzEWqsee8fs6SefCGuuXPV+W+xZ8IJzxztxWO/eBS/Qd+AEfCsO5Jak3AzbbrL42DbmNq1wWkmNE+5qBEJL0qRxjq23Vn/ghXJPT8Xn6cEvPWqttXLVC0sejnbCmp3tuEaSWsZ1dmXorTU0Q4SnjFDxPPfuk6weWXWtwrnOvP13soa9q8xc7AXSGM8Np0aSKmPIQG/fMWutvYePW3UbX743rJmb84KX9+3fa9VdvHQlrBmPze+AQXzMOm13YITXH2RGMH2eeUH4Lt7wAQAAJI6GDwAAIHE0fAAAAImj4QMAAEgcDR8AAEDiaPgAAAASR8MHAACQOBo+AACAxNHwAQAAJM6etNHueWn4TgtZN17KemFM2nBT7rc2N626naYKa1o75mEzp4DUVbzN2fk5a63Vi3H6+HR7YK11wwlvIsd4Zyus+dJDD1trXb5yzapbX1kPa44e9KbDLB3YE9bMTvestdqll4zuhP5PcjNl3ZwgkOdxXVHu3m/AsjQnzZh1Bw/GCfa1mUz/pUeftOqeOn8urFkee8+gkTHFZ2xOUyjM1P+6jp8txmAGSdJw23uGFsYUlsx4zkru5Bd3gsY37qQNR+ZOCnFOaMebenHkZbdZdf/ziQfDmq3Gu9C6A2/fpmfi62ztSvx9KElra/Hknf17F6y1Zgbed0WrjM/nxLtNbLzhAwAASBwNHwAAQOJo+AAAABJHwwcAAJA4Gj4AAIDE0fABAAAkjoYPAAAgcTR8AAAAiaPhAwAASJw9acNNvx7vGGns5qSNxoiZdmokaXt726qru62wZmwk5kvSoNW26tavxSnf03PT1lq9Trz/ZeVNoGiZUxduOH4orLmysmKt9cgjp6y6q5c3wprzy/FxlaRjq3HdIWMahyTNz7jnKU5jtwdtmD/bSmMKSMe4fiSpKOKNOpM9JCkvvW0O+vH+nzyxZK21uHfWqnvJytGw5ktPx9M4JOmR0xfDmuXlq9ZaReE9ussynpBUmRMQhsZEHUnauBZ/hkVrgoa0q4M2voHZUzQMzm1XmYd/z4mXW3WHvu0vhDWXH/mctdZi7U2uyfP4ui1b3rNluBP3B1tb8XeOJGXzU1bdVC+uGzNpAwAAAM8HDR8AAEDiaPgAAAASR8MHAACQOBo+AACAxNHwAQAAJI6GDwAAIHE0fAAAAImzg5fH1cSqqxSHKje1t5bqeK2JGYI8NIOX8058SMYjb5vbZmriZBIfj4sXL1lrTRkppH0zqbfT7lh16scB0zedvMFaamPdC4V+8OHTYc3FVS8Q97QRCr20d95a6+iSF/y7d34xrJnue6GhbkB2px1f29MzA2utrhHQnFfe46UuvPukZSTK1uY9V+2sW3VZHYcNd7teQrYTat1pe+d8esYLjm4b93DXCICVpNJ8buxsxse2mXjP0Kw0E4K/CThBw5Kk2hhYkHnDD8Yd79o4+X99b1gzPe2F0j/xu/+vVdcyhi4sLnqB+b1WfA+3cu+YTcxeyeldOl3veeziDR8AAEDiaPgAAAASR8MHAACQOBo+AACAxNHwAQAAJI6GDwAAIHE0fAAAAImj4QMAAEgcDR8AAEDi7EkbZsi6RuN4UsK0kTgvSZNJPB2jMdOvG2MCiCTlRrB7WXqHLc+8un67F9asnD9jrTU29j8rvQkaC2bdtJEGfuSAN41g56XeRJTla1fDmkdOXbDWWlmOE9tPLY+stb789JpVt382Pmb793jJ9AtzXhr+4mxct2dnx1prZqob1pQt7/qvzAkCrSqetDEZeZM2lte983RxayOsWTenw4y24qkd5qANKfOux7qJj+1oHO+XJBWKz7kkjbbiY1uNvess7zgPNGspuTM7zOW+7rLM27PMmEijxjsa7vd+bXwnHrz5z1lrTU950yUuP/WFsOZA4U10mdmJ76cq89Zq2t53XbeJj1l7lyfN8IYPAAAgcTR8AAAAiaPhAwAASBwNHwAAQOJo+AAAABJHwwcAAJA4Gj4AAIDE0fABAAAkjoYPAAAgcfakjcZM5nbKWu22tdZkGCfYt9reNIiqNhOrR3Gadjt3D5uX+l8YEzmurK5Ya125eC2seemxm6y1Ci9YX40RLN4ypolI0vGjx6y60TA+T2Nz6sLDTy+HNRsjb7LBmaE3QeDCSnw+e6e9ZP3ZaS+Z/sC++bDm2KED1lqLCzNhTb/vnfOqNqfljOK60bY39eLajjfR5ZoxOeiKu821+N5sd73nWV1713ZZxDen/avf/A5Yv7Ya1mwYNZI001+MizJvsoE9Q+MbddSGKTM+QMscoeGsJUlZJ/5OL9re5KCZm19q1c3uj59nq08/bK2VK56o01TxdCdJagrz2FbxF2wznnhrWVW84QMAAEgeDR8AAEDiaPgAAAASR8MHAACQOBo+AACAxNHwAQAAJI6GDwAAIHE0fAAAAImzg5dbpReWnOdxCOak8oJW2904uLU/44U5TiZeNGFdxeGiW9ub1lpTPS+5+Oraelhz5vwFa61HH4vrlo683Frr6Ow+qy4v4/M5No+ZjBBqSTq+tD+s2brlRmuttc04VPmp5TiYU5I2Rl447VYTX4/rXjawlne8fTuzuhXWfPmcF/A9PdUPa+Zm43BmSWqX3jnPjcfG2AjklqRR4wUXD2WEPdfeNvMy/n1txsNrYSEOnZWkqak4lHt6MOVtc37BqpuMjVD0HfN5UBnHNve+mxozoPlFnrtsyc13PS3zaOSFU9ey1nIDvvtzh8Oa7S0vMP/a6kNhzezAC0VvJl5Ycu5ct5V3bbt4wwcAAJA4Gj4AAIDE0fABAAAkjoYPAAAgcTR8AAAAiaPhAwAASBwNHwAAQOJo+AAAABJHwwcAAJA4e9JGNfaS6cejOGV6x2wze914UkW7HyfJS9L68qpVN2jHadrVxEvWH5p1q2vxSIUnn1621nrqbDwp4enzF621XvFSb1JFbzo+T4WZcr+56X3OkZHmv2+vN43gFbecDGs2vvCotdbOSjw1RZImxq1XZd6NMq68e3NSxWn4m2s71lpnr8bTPbqXrlprzc14EznKPD4eOzveeJK88I5tncWp/52eN0FgZjqeTtLtx9OFJKnT8VL/Vcf7706W6BjPY0lqdeLpAJOdeOrLHxWGJXnbO2bupA1nzsM38jSOzNo77xO4n9M5srW5WpOZEzmMutn5I9ZSF1ZOhTXbq2vWWjMtc3JQO57i05gTzly84QMAAEgcDR8AAEDiaPgAAAASR8MHAACQOBo+AACAxNHwAQAAJI6GDwAAIHE0fAAAAImzg5dbpRf02W7FdY0RZvpMXdyPVo231mgSB0JL0mwRR0hOGq9PHo7iYEVJunZtFNacORMH3UpSXcen9NFHvmit9d+2vODck0cOhjUnjhy11ppU3rHdMgJlt2ov+Hpxz2xYc+zgPmutre34XErS1Y24biczY08br66q44Bm+940QlTNy1+rW14I79R0HLI+zLyN5nLr4uNR1d7xL9pxUGyRe+HAVjqwpIkRUF6Ygbi1eT5LI9R6a8MLsa2reP9z41kg+dd27t5336iM/TcvHzt4OTNWzM3nlN+WGJ+i5YWF9+ZvCGsu/uEFb605b/87i87+m88DE2/4AAAAEkfDBwAAkDgaPgAAgMTR8AEAACSOhg8AACBxNHwAAACJo+EDAABIHA0fAABA4mj4AAAAEmdP2mgaL2a9NJLiJ6Mda62dajusGQ+9aQqFmbJeGsHWO9vesdgZetM9Ll28Etb0296kk9d++61hzbGleLKEJK1d9SZtfOHBz4c1n//Cg9Zax47HieeStHRgLqzZNEc9rFy9Ftb0+z1rrYXZaatuPI63Odn2ru3MnBoxMiaP9HredVYZm8zNp0st7z5pivgebvXa3jaNCQ6S1MriB0Kr9D5oz7iGSnOtqal46ogkZcZ4jLaZ5r9jTkTpDOJ7YHNj1Vpraz1+Bs0M5q21/K+7F/ekDeebzp204VY6R2y3j2qTx9f2KPf2f2op/t7Zuuh9H54++wWrbl8vvu86xuQvSfK+nXjDBwAAkDwaPgAAgMTR8AEAACSOhg8AACBxNHwAAACJo+EDAABIHA0fAABA4mj4AAAAEkfDBwAAkDh/0oaR0i9JTVWFNcMNb9JG0euGNdWOt1ZpTiPY2dkMazY2RtZaa2te3XB9Nay5/XUvs9Z66fH9YU3PbPPHe70E+5WlpbDmzIVL1lqPP/mIVffwl+Pr8cD+Q9Za4zq+DbbM6TCFORGl3YknQhTmFJlq7F3b3XYrrJka9K21dkbDsGZSx88CSVLhXZD7lw6GNaNhvF+SdOHsWauu147PU6f0znkzic9TbTw/JSkzJx+1W/GxLQtvBkLXOBbuelnh7X/VxOezabznbC7vPL3Y7e7Ui12cj7HLozYyY3pWq/SeLZMsvjYWb/1Wa61T29533erK02HN3ucxE8XBGz4AAIDE0fABAAAkjoYPAAAgcTR8AAAAiaPhAwAASBwNHwAAQOJo+AAAABJHwwcAAJA4O3i5NsM51YnDXdvywl3rOg4dHNvhroVV1uTx/u8MN6y1Lp73wl33z82ENa84ccJaa08/7uHziRcibOb+quzEoZX9/XuttfZ0vUvyyYvLYc2pU09Ya40n8XXW609ba2W1FwLba8fXY1HG16IkdVpeXV7Ex3Z2fo+1VnPtWlgz2vDuk9IMxG0VvbBmccm7zlavXrXqijy+nzL32VjHYcOlGUI9HnvXmZPP3Jl491zLeLZLUp7Hx6PMvGPWso6HF07bmOH7mbzvCrywMiPJuTC/951U6LzrPacO33CjVXfq954Ma6a729ZaA6uKN3wAAADJo+EDAABIHA0fAABA4mj4AAAAEkfDBwAAkDgaPgAAgMTR8AEAACSOhg8AACBxNHwAAACJy5qm8WLKAQAA8KLEGz4AAIDE0fABAAAkjoYPAAAgcTR8AAAAiaPhAwAASBwNHwAAQOJo+AAAABJHwwcAAJA4Gj4AAIDE/f/MIsguKs5DygAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "# Now you can iterate over the dataloader\n",
    "for i, images in enumerate(train_dataloader):\n",
    "    # Choose just one image to display from the batch\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Training Images\")\n",
    "    # Convert the tensor to a numpy array and transpose the dimensions from (C, H, W) to (H, W, C)\n",
    "    plt.imshow(images[0].permute(1, 2, 0).numpy().clip(0, 1))\n",
    "    plt.show()\n",
    "    \n",
    "    # Break after the first image to prevent displaying all images\n",
    "    if i == 0:  # display just one batch or modify as per requirement\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45183043",
   "metadata": {},
   "source": [
    "## Basic Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffad513e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "class ConvEncoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(ConvEncoder, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=(3,3), stride=(2,2), padding=1) # assuming input image size is 3 x 64 x 64\n",
    "        self.batchnorm1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=(3,3), stride=(2,2), padding=1)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(64)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=(3,3), stride=(2,2), padding=1)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=(3,3), stride=(2,2), padding=1)\n",
    "        self.batchnorm4 = nn.BatchNorm2d(256)\n",
    "        self.conv5 = nn.Conv2d(256, 512, kernel_size=(3,3), stride=(2,2), padding=1)\n",
    "        self.batchnorm5 = nn.BatchNorm2d(512)\n",
    "        self.fc_mu = nn.Linear(2048, latent_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.batchnorm1(x))\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(self.batchnorm2(x))\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(self.batchnorm3(x))\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(self.batchnorm4(x))\n",
    "        x = self.conv5(x)\n",
    "        x = F.relu(self.batchnorm5(x))\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        mu = self.fc_mu(x)\n",
    "        return mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aba4321b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder\n",
    "class ConvDecoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(ConvDecoder, self).__init__()\n",
    "        self.fc = nn.Linear(latent_dim, 2048)\n",
    "        self.deconv1 = nn.ConvTranspose2d(512, 256, kernel_size=(3,3), stride=(2,2), padding=1, output_padding=1)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(256)\n",
    "        self.deconv2 = nn.ConvTranspose2d(256, 128, kernel_size=(3,3), stride=(2,2), padding=1, output_padding=1)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(128)\n",
    "        self.deconv3 = nn.ConvTranspose2d(128, 64, kernel_size=(3,3), stride=(2,2), padding=1, output_padding=1)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(64)\n",
    "        self.deconv4 = nn.ConvTranspose2d(64, 32, kernel_size=(3,3), stride=(2,2), padding=1, output_padding=1)\n",
    "        self.batchnorm4 = nn.BatchNorm2d(32)\n",
    "        self.deconv5 = nn.ConvTranspose2d(32, 32, kernel_size=(3,3), stride=(2,2), padding=1, output_padding=1)\n",
    "        self.batchnorm5 = nn.BatchNorm2d(32)\n",
    "        self.conv = nn.Conv2d(32, 3, kernel_size=(3,3), stride=(1,1), padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = x.view(-1, 512, 2, 2) # reshaping to match the corresponding encoder shape\n",
    "        x = self.deconv1(x)\n",
    "        x = F.relu(self.batchnorm1(x))\n",
    "        x = self.deconv2(x)\n",
    "        x = F.relu(self.batchnorm2(x))\n",
    "        x = self.deconv3(x)\n",
    "        x = F.relu(self.batchnorm3(x))\n",
    "        x = self.deconv4(x)\n",
    "        x = F.relu(self.batchnorm4(x))\n",
    "        x = self.deconv5(x)\n",
    "        x = F.relu(self.batchnorm5(x))\n",
    "        x = self.conv(x)\n",
    "        reconstruction = torch.tanh(x) # Using sigmoid for final layer to output values between 0 and 1\n",
    "        return reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06e3576d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# variational autoencoder\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = ConvEncoder(latent_dim)\n",
    "        self.decoder = ConvDecoder(latent_dim)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std, std\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu = self.encoder(x)\n",
    "        return self.decoder(mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0d9ba8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "def vae_loss(recon_x, x, mu, std):\n",
    "    mu = mu.to(device)\n",
    "    std = std.to(device)\n",
    "    BCE = F.mse_loss(recon_x, x, reduction='mean')\n",
    "    KLD = -0.5 * torch.sum(1 + 2*std - (2*std).exp() - mu.pow(2))\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07381920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(recon_x, x):\n",
    "    loss = F.mse_loss(recon_x, x, reduction='mean')\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9da4f2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Function to save data to CSV\n",
    "def save_to_csv(epoch, loss, filename):\n",
    "    with open(filename, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([epoch, loss])\n",
    "\n",
    "# Example usage in a training loop\n",
    "filename = '200k_training_log.csv'\n",
    "\n",
    "# Initialize or clear the file with headers\n",
    "with open(filename, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Epoch\", \"Loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c1ee204",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ae(model, dataloader, optimizer, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = 0\n",
    "#         print(\"epoch: {}\".format(epoch))\n",
    "        for batch_idx, data in enumerate(dataloader):\n",
    "#             print(\"batch number: {}\".format(batch_idx))\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "#             data.flatten(2)\n",
    "#             recon_batch, mu, std = model(data)\n",
    "            recon_batch = model(data)\n",
    "#             print(recon_batch)\n",
    "#             loss = vae_loss(recon_batch, data, mu, std)\n",
    "            loss = loss_fn(recon_batch, data)\n",
    "            loss.backward()\n",
    "            train_loss += loss.item()\n",
    "            optimizer.step()\n",
    "        print('Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(dataloader.dataset)))\n",
    "        save_to_csv(epoch,  train_loss / len(dataloader.dataset), filename)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b718ca9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Average loss: 0.0003\n",
      "Epoch: 1 Average loss: 0.0001\n",
      "Epoch: 2 Average loss: 0.0001\n",
      "Epoch: 3 Average loss: 0.0001\n",
      "Epoch: 4 Average loss: 0.0001\n",
      "Epoch: 5 Average loss: 0.0001\n",
      "Epoch: 6 Average loss: 0.0001\n",
      "Epoch: 7 Average loss: 0.0001\n",
      "Epoch: 8 Average loss: 0.0001\n",
      "Epoch: 9 Average loss: 0.0001\n",
      "Epoch: 10 Average loss: 0.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Train the VAE\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m vae_model \u001b[38;5;241m=\u001b[39m train_vae(model, train_loader, optimizer, epochs)\n",
      "Cell \u001b[0;32mIn[16], line 32\u001b[0m, in \u001b[0;36mtrain_vae\u001b[0;34m(model, dataloader, optimizer, epochs)\u001b[0m\n\u001b[1;32m     30\u001b[0m         train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m#         print(\"epoch: {}\".format(epoch))\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m#             print(\"batch number: {}\".format(batch_idx))\u001b[39;00m\n\u001b[1;32m     34\u001b[0m             data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     35\u001b[0m             optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[6], line 27\u001b[0m, in \u001b[0;36mCelebADataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     24\u001b[0m image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(img_name)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[0;32m---> 27\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(image)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m image\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m t(img)\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torchvision/transforms/transforms.py:361\u001b[0m, in \u001b[0;36mResize.forward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m    354\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;124;03m        img (PIL Image or Tensor): Image to be scaled.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;124;03m        PIL Image or Tensor: Rescaled image.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 361\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mresize(img, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterpolation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mantialias)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torchvision/transforms/functional.py:490\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    488\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnti-alias option is always applied for PIL Image input. Argument antialias is ignored.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    489\u001b[0m     pil_interpolation \u001b[38;5;241m=\u001b[39m pil_modes_mapping[interpolation]\n\u001b[0;32m--> 490\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F_pil\u001b[38;5;241m.\u001b[39mresize(img, size\u001b[38;5;241m=\u001b[39moutput_size, interpolation\u001b[38;5;241m=\u001b[39mpil_interpolation)\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F_t\u001b[38;5;241m.\u001b[39mresize(img, size\u001b[38;5;241m=\u001b[39moutput_size, interpolation\u001b[38;5;241m=\u001b[39minterpolation\u001b[38;5;241m.\u001b[39mvalue, antialias\u001b[38;5;241m=\u001b[39mantialias)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torchvision/transforms/_functional_pil.py:250\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(size, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(size) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot inappropriate size arg: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 250\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img\u001b[38;5;241m.\u001b[39mresize(\u001b[38;5;28mtuple\u001b[39m(size[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]), interpolation)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/PIL/Image.py:2156\u001b[0m, in \u001b[0;36mImage.resize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   2154\u001b[0m size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(size)\n\u001b[0;32m-> 2156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload()\n\u001b[1;32m   2157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m box \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2158\u001b[0m     box \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/PIL/ImageFile.py:269\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[1;32m    268\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[0;32m--> 269\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m decoder\u001b[38;5;241m.\u001b[39mdecode(b)\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "train_loader = train_dataloader\n",
    "model = VAE(latent_dim)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# Train the VAE\n",
    "vae_model = train_vae(model, train_loader, optimizer, epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5aa74257",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataloader):\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#     print(batch_idx)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 5\u001b[0m     recon_batch, mu, logvar \u001b[38;5;241m=\u001b[39m model(data)\n\u001b[1;32m      6\u001b[0m     std \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m logvar)\n\u001b[1;32m      7\u001b[0m     eps \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn_like(std)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "vector = []\n",
    "for batch_idx, data in enumerate(train_dataloader):\n",
    "#     print(batch_idx)\n",
    "    data = data.to(device)\n",
    "    recon_batch, mu, logvar = model(data)\n",
    "    std = torch.exp(0.5 * logvar)\n",
    "    eps = torch.randn_like(std)\n",
    "    temp = mu + eps * std\n",
    "    temp = temp.cpu()\n",
    "    for i in range(len(temp)):\n",
    "        val = temp[i][0].detach().numpy()\n",
    "#         print(type(val))\n",
    "        vector.append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50df5a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b82e7b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.patches.StepPatch at 0x2eb404890>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjgAAAGdCAYAAAAfTAk2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAfeklEQVR4nO3da3DU5d3/8c9CwgYsWZFIQiRCsMihVCvJEBMnxfbGcFCRFkeUmqqj1IxjOWSsgNiCeA8Z0FJKw6HSoHUGkVHE8iCmxL+aRgkgNEELKXY0AgorBiEbxQYI1/8Bw95dE0I2dTfsl/drZh/kyvXbvX7XoPvmtwc8zjknAAAAQ7p09gIAAAC+bQQOAAAwh8ABAADmEDgAAMAcAgcAAJhD4AAAAHMIHAAAYA6BAwAAzInr7AV0htOnT+vgwYPq2bOnPB5PZy8HAAC0g3NOjY2NSk1NVZcubV+juSgD5+DBg0pLS+vsZQAAgA44cOCA+vXr1+acizJwevbsKenMBiUmJnbyagAAQHsEAgGlpaUFn8fbclEGztmXpRITEwkcAABiTHveXsKbjAEAgDkEDgAAMIfAAQAA5hA4AADAHAIHAACYQ+AAAABzCBwAAGAOgQMAAMwhcAAAgDkEDgAAMIfAAQAA5hA4AADAHAIHAACYQ+AAAABzCBwAAGAOgQMAAMwhcAAAgDkEDgAAMIfAAQAA5hA4AADAHAIHAACYQ+AAAABzCBwAAGAOgQMAAMwhcAAAgDkEDgAAMIfAAQAA5hA4AADAHAIHAACYQ+AAAABzCBwAAGAOgQMAAMwhcAAAgDkEDgAAMIfAAQAA5hA4AADAHAIHAACYQ+AAAABzCBwAAGAOgQMAAMwhcAAAgDkEDgAAMIfAAQAA5kQlcFasWKH09HQlJCQoIyNDlZWVbc6vqKhQRkaGEhISNHDgQK1ateqcc1988UV5PB5NnDjxW141AACIVREPnPXr12vGjBmaO3euqqurlZubq3Hjxmn//v2tzq+rq9P48eOVm5ur6upqPfbYY5o2bZo2bNjQYu6+ffv0yCOPKDc3N9KnAQAAYojHOeci+QBZWVkaMWKEVq5cGRwbOnSoJk6cqKKiohbzZ82apU2bNqm2tjY4VlBQoF27dqmqqio41tzcrFGjRum+++5TZWWljh07pldffbVdawoEAvL5fGpoaFBiYmLHTw4AAERNOM/fEb2Cc+LECe3cuVN5eXkh43l5edqyZUurx1RVVbWYP2bMGO3YsUMnT54Mji1YsECXX3657r///vOuo6mpSYFAIOQGAADsimjg1NfXq7m5WcnJySHjycnJ8vv9rR7j9/tbnX/q1CnV19dLkt555x2VlJRo9erV7VpHUVGRfD5f8JaWltaBswEAALEiKm8y9ng8IT8751qMnW/+2fHGxkbdfffdWr16tZKSktr1+HPmzFFDQ0PwduDAgTDPAAAAxJK4SN55UlKSunbt2uJqzeHDh1tcpTkrJSWl1flxcXHq3bu3du/erY8//li33npr8PenT5+WJMXFxWnv3r266qqrQo73er3yer3fxikBAIAYENErON26dVNGRobKy8tDxsvLy5WTk9PqMdnZ2S3mb968WZmZmYqPj9eQIUP0/vvvq6amJnibMGGCfvSjH6mmpoaXnwAAQGSv4EhSYWGh8vPzlZmZqezsbD3zzDPav3+/CgoKJJ15+ejTTz/V888/L+nMJ6aKi4tVWFioqVOnqqqqSiUlJVq3bp0kKSEhQcOHDw95jEsvvVSSWowDAICLU8QDZ/LkyTpy5IgWLFigQ4cOafjw4SotLVX//v0lSYcOHQr5Tpz09HSVlpZq5syZWr58uVJTU7Vs2TJNmjQp0ksFAABGRPx7cC5EfA8OAACx54L5HhwAAIDOQOAAAABzCBwAAGAOgQMAAMwhcAAAgDkEDgAAMIfAAQAA5hA4AADAHAIHAACYQ+AAAABzCBwAAGAOgQMAAMwhcAAAgDkEDgAAMIfAAQAA5hA4AADAHAIHAACYQ+AAAABzCBwAAGAOgQMAAMwhcAAAgDkEDgAAMIfAAQAA5hA4AADAHAIHAACYQ+AAAABzCBwAAGAOgQMAAMwhcAAAgDkEDgAAMIfAAQAA5hA4AADAHAIHAACYQ+AAAABzCBwAAGAOgQMAAMwhcAAAgDkEDgAAMIfAAQAA5hA4AADAHAIHAACYQ+AAAABzCBwAAGAOgQMAAMwhcAAAgDkEDgAAMIfAAQAA5hA4AADAHAIHAACYQ+AAAABzCBwAAGAOgQMAAMwhcAAAgDkEDgAAMIfAAQAA5hA4AADAnKgEzooVK5Senq6EhARlZGSosrKyzfkVFRXKyMhQQkKCBg4cqFWrVoX8fvXq1crNzVWvXr3Uq1cvjR49Wtu3b4/kKQAAgBgS8cBZv369ZsyYoblz56q6ulq5ubkaN26c9u/f3+r8uro6jR8/Xrm5uaqurtZjjz2madOmacOGDcE5b731lu666y69+eabqqqq0pVXXqm8vDx9+umnkT4dAAAQAzzOORfJB8jKytKIESO0cuXK4NjQoUM1ceJEFRUVtZg/a9Ysbdq0SbW1tcGxgoIC7dq1S1VVVa0+RnNzs3r16qXi4mL9/Oc/P++aAoGAfD6fGhoalJiY2IGzAgAA0RbO83dEr+CcOHFCO3fuVF5eXsh4Xl6etmzZ0uoxVVVVLeaPGTNGO3bs0MmTJ1s95vjx4zp58qQuu+yyVn/f1NSkQCAQcgMAAHZFNHDq6+vV3Nys5OTkkPHk5GT5/f5Wj/H7/a3OP3XqlOrr61s9Zvbs2briiis0evToVn9fVFQkn88XvKWlpXXgbAAAQKyIypuMPR5PyM/OuRZj55vf2rgkLV68WOvWrdMrr7yihISEVu9vzpw5amhoCN4OHDgQ7ikAAIAYEhfJO09KSlLXrl1bXK05fPhwi6s0Z6WkpLQ6Py4uTr179w4Zf/rpp7Vw4UK9/vrruuaaa865Dq/XK6/X28GzAAAAsSaiV3C6deumjIwMlZeXh4yXl5crJyen1WOys7NbzN+8ebMyMzMVHx8fHHvqqaf05JNPqqysTJmZmd/+4gEAQMyK+EtUhYWF+tOf/qQ1a9aotrZWM2fO1P79+1VQUCDpzMtH//nJp4KCAu3bt0+FhYWqra3VmjVrVFJSokceeSQ4Z/HixXr88ce1Zs0aDRgwQH6/X36/X19++WWkTwcAAMSAiL5EJUmTJ0/WkSNHtGDBAh06dEjDhw9XaWmp+vfvL0k6dOhQyHfipKenq7S0VDNnztTy5cuVmpqqZcuWadKkScE5K1as0IkTJ3T77beHPNa8efM0f/78SJ8SAAC4wEX8e3AuRHwPDgAAseeC+R4cAACAzkDgAAAAcwgcAABgDoEDAADMIXAAAIA5BA4AADCHwAEAAOYQOAAAwBwCBwAAmEPgAAAAcwgcAABgDoEDAADMIXAAAIA5BA4AADCHwAEAAOYQOAAAwBwCBwAAmEPgAAAAcwgcAABgDoEDAADMIXAAAIA5BA4AADCHwAEAAOYQOAAAwBwCBwAAmEPgAAAAcwgcAABgDoEDAADMIXAAAIA5BA4AADCHwAEAAOYQOAAAwBwCBwAAmEPgAAAAcwgcAABgDoEDAADMIXAAAIA5BA4AADCHwAEAAOYQOAAAwBwCBwAAmEPgAAAAcwgcAABgDoEDAADMIXAAAIA5BA4AADCHwAEAAOYQOAAAwBwCBwAAmEPgAAAAcwgcAABgDoEDAADMIXAAAIA5BA4AADCHwAEAAOYQOAAAwJyoBM6KFSuUnp6uhIQEZWRkqLKyss35FRUVysjIUEJCggYOHKhVq1a1mLNhwwYNGzZMXq9Xw4YN08aNGyO1fAAAEGMiHjjr16/XjBkzNHfuXFVXVys3N1fjxo3T/v37W51fV1en8ePHKzc3V9XV1Xrsscc0bdo0bdiwITinqqpKkydPVn5+vnbt2qX8/Hzdcccd2rZtW6RPBwAAxACPc85F8gGysrI0YsQIrVy5Mjg2dOhQTZw4UUVFRS3mz5o1S5s2bVJtbW1wrKCgQLt27VJVVZUkafLkyQoEAnrttdeCc8aOHatevXpp3bp1511TIBCQz+dTQ0ODEhMT/5vTAwAAURLO83dcJBdy4sQJ7dy5U7Nnzw4Zz8vL05YtW1o9pqqqSnl5eSFjY8aMUUlJiU6ePKn4+HhVVVVp5syZLeYsXbq01ftsampSU1NT8OdAINCBs2m/w4F/63Bj0/knAgBgVJ+eXvVJTOi0x49o4NTX16u5uVnJyckh48nJyfL7/a0e4/f7W51/6tQp1dfXq2/fvuecc677LCoq0hNPPPFfnEl41m7br9//v39F7fEAALjQTP+fQZp509Wd9vgRDZyzPB5PyM/OuRZj55v/zfFw7nPOnDkqLCwM/hwIBJSWlta+xXfAz7Ku1E3Dks8/EQAAo/r09Hbq40c0cJKSktS1a9cWV1YOHz7c4grMWSkpKa3Oj4uLU+/evducc6779Hq98nqjt9F9EhM69bIcAAAXu4h+iqpbt27KyMhQeXl5yHh5eblycnJaPSY7O7vF/M2bNyszM1Px8fFtzjnXfQIAgItLxF+iKiwsVH5+vjIzM5Wdna1nnnlG+/fvV0FBgaQzLx99+umnev755yWd+cRUcXGxCgsLNXXqVFVVVamkpCTk01HTp0/XD3/4Qy1atEi33Xab/vKXv+j111/X22+/HenTAQAAMSDigTN58mQdOXJECxYs0KFDhzR8+HCVlpaqf//+kqRDhw6FfCdOenq6SktLNXPmTC1fvlypqalatmyZJk2aFJyTk5OjF198UY8//rh+/etf66qrrtL69euVlZUV6dMBAAAxIOLfg3Mh4ntwAACIPeE8f/NvUQEAAHMIHAAAYA6BAwAAzCFwAACAOQQOAAAwh8ABAADmEDgAAMAcAgcAAJhD4AAAAHMIHAAAYA6BAwAAzCFwAACAOQQOAAAwh8ABAADmEDgAAMAcAgcAAJhD4AAAAHMIHAAAYA6BAwAAzCFwAACAOQQOAAAwh8ABAADmEDgAAMAcAgcAAJhD4AAAAHMIHAAAYA6BAwAAzCFwAACAOQQOAAAwh8ABAADmEDgAAMAcAgcAAJhD4AAAAHMIHAAAYA6BAwAAzCFwAACAOQQOAAAwh8ABAADmEDgAAMAcAgcAAJhD4AAAAHMIHAAAYA6BAwAAzCFwAACAOQQOAAAwh8ABAADmEDgAAMAcAgcAAJhD4AAAAHMIHAAAYA6BAwAAzCFwAACAOQQOAAAwh8ABAADmEDgAAMAcAgcAAJgT0cA5evSo8vPz5fP55PP5lJ+fr2PHjrV5jHNO8+fPV2pqqrp3764bb7xRu3fvDv7+iy++0C9/+UsNHjxYPXr00JVXXqlp06apoaEhkqcCAABiSEQDZ8qUKaqpqVFZWZnKyspUU1Oj/Pz8No9ZvHixlixZouLiYr377rtKSUnRTTfdpMbGRknSwYMHdfDgQT399NN6//339dxzz6msrEz3339/JE8FAADEEI9zzkXijmtrazVs2DBt3bpVWVlZkqStW7cqOztb//znPzV48OAWxzjnlJqaqhkzZmjWrFmSpKamJiUnJ2vRokV68MEHW32sl156SXfffbe++uorxcXFnXdtgUBAPp9PDQ0NSkxM/C/OEgAAREs4z98Ru4JTVVUln88XjBtJuv766+Xz+bRly5ZWj6mrq5Pf71deXl5wzOv1atSoUec8RlLwRNsTNwAAwL6IFYHf71efPn1ajPfp00d+v/+cx0hScnJyyHhycrL27dvX6jFHjhzRk08+ec6rO9KZq0BNTU3BnwOBwHnXDwAAYlfYV3Dmz58vj8fT5m3Hjh2SJI/H0+J451yr4//pm78/1zGBQEA333yzhg0bpnnz5p3z/oqKioJvdPb5fEpLS2vPqQIAgBgV9hWchx9+WHfeeWebcwYMGKD33ntPn332WYvfff755y2u0JyVkpIi6cyVnL59+wbHDx8+3OKYxsZGjR07Vt/5zne0ceNGxcfHn3M9c+bMUWFhYfDnQCBA5AAAYFjYgZOUlKSkpKTzzsvOzlZDQ4O2b9+ukSNHSpK2bdumhoYG5eTktHpMenq6UlJSVF5eruuuu06SdOLECVVUVGjRokXBeYFAQGPGjJHX69WmTZuUkJDQ5lq8Xq+8Xm97TxEAAMS4iL3JeOjQoRo7dqymTp2qrVu3auvWrZo6dapuueWWkE9QDRkyRBs3bpR05qWpGTNmaOHChdq4caP+8Y9/6N5771WPHj00ZcoUSWeu3OTl5emrr75SSUmJAoGA/H6//H6/mpubI3U6AAAghkT0Y0dr167VtGnTgp+KmjBhgoqLi0Pm7N27N+RL+h599FF9/fXXeuihh3T06FFlZWVp8+bN6tmzpyRp586d2rZtmyTpu9/9bsh91dXVacCAARE8IwAAEAsi9j04FzK+BwcAgNhzQXwPDgAAQGchcAAAgDkEDgAAMIfAAQAA5hA4AADAHAIHAACYQ+AAAABzCBwAAGAOgQMAAMwhcAAAgDkEDgAAMIfAAQAA5hA4AADAHAIHAACYQ+AAAABzCBwAAGAOgQMAAMwhcAAAgDkEDgAAMIfAAQAA5hA4AADAHAIHAACYQ+AAAABzCBwAAGAOgQMAAMwhcAAAgDkEDgAAMIfAAQAA5hA4AADAHAIHAACYQ+AAAABzCBwAAGAOgQMAAMwhcAAAgDkEDgAAMIfAAQAA5hA4AADAHAIHAACYQ+AAAABzCBwAAGAOgQMAAMwhcAAAgDkEDgAAMIfAAQAA5hA4AADAHAIHAACYQ+AAAABzCBwAAGAOgQMAAMwhcAAAgDkEDgAAMIfAAQAA5hA4AADAHAIHAACYQ+AAAABzCBwAAGAOgQMAAMyJaOAcPXpU+fn58vl88vl8ys/P17Fjx9o8xjmn+fPnKzU1Vd27d9eNN96o3bt3n3PuuHHj5PF49Oqrr377JwAAAGJSRANnypQpqqmpUVlZmcrKylRTU6P8/Pw2j1m8eLGWLFmi4uJivfvuu0pJSdFNN92kxsbGFnOXLl0qj8cTqeUDAIAYFRepO66trVVZWZm2bt2qrKwsSdLq1auVnZ2tvXv3avDgwS2Occ5p6dKlmjt3rn76059Kkv785z8rOTlZL7zwgh588MHg3F27dmnJkiV699131bdv30idBgAAiEERu4JTVVUln88XjBtJuv766+Xz+bRly5ZWj6mrq5Pf71deXl5wzOv1atSoUSHHHD9+XHfddZeKi4uVkpJy3rU0NTUpEAiE3AAAgF0RCxy/368+ffq0GO/Tp4/8fv85j5Gk5OTkkPHk5OSQY2bOnKmcnBzddttt7VpLUVFR8H1APp9PaWlp7T0NAAAQg8IOnPnz58vj8bR527FjhyS1+v4Y59x53zfzzd//5zGbNm3SG2+8oaVLl7Z7zXPmzFFDQ0PwduDAgXYfCwAAYk/Y78F5+OGHdeedd7Y5Z8CAAXrvvff02Weftfjd559/3uIKzVlnX27y+/0h76s5fPhw8Jg33nhDH374oS699NKQYydNmqTc3Fy99dZbLe7X6/XK6/W2uWYAAGBH2IGTlJSkpKSk887Lzs5WQ0ODtm/frpEjR0qStm3bpoaGBuXk5LR6THp6ulJSUlReXq7rrrtOknTixAlVVFRo0aJFkqTZs2frgQceCDnu+9//vn73u9/p1ltvDfd0AACAQRH7FNXQoUM1duxYTZ06VX/84x8lSb/4xS90yy23hHyCasiQISoqKtJPfvITeTwezZgxQwsXLtSgQYM0aNAgLVy4UD169NCUKVMknbnK09obi6+88kqlp6dH6nQAAEAMiVjgSNLatWs1bdq04KeiJkyYoOLi4pA5e/fuVUNDQ/DnRx99VF9//bUeeughHT16VFlZWdq8ebN69uwZyaUCAABDPM4519mLiLZAICCfz6eGhgYlJiZ29nIAAEA7hPP8zb9FBQAAzCFwAACAOQQOAAAwh8ABAADmEDgAAMAcAgcAAJhD4AAAAHMIHAAAYA6BAwAAzCFwAACAOQQOAAAwh8ABAADmEDgAAMAcAgcAAJhD4AAAAHMIHAAAYA6BAwAAzCFwAACAOQQOAAAwh8ABAADmEDgAAMAcAgcAAJhD4AAAAHMIHAAAYA6BAwAAzCFwAACAOQQOAAAwh8ABAADmEDgAAMAcAgcAAJhD4AAAAHMIHAAAYA6BAwAAzCFwAACAOQQOAAAwh8ABAADmEDgAAMAcAgcAAJhD4AAAAHMIHAAAYA6BAwAAzCFwAACAOXGdvYDO4JyTJAUCgU5eCQAAaK+zz9tnn8fbclEGTmNjoyQpLS2tk1cCAADC1djYKJ/P1+Ycj2tPBhlz+vRpHTx4UD179pTH4/lW7zsQCCgtLU0HDhxQYmLit3rf+D/sc3Swz9HBPkcPex0dkdpn55waGxuVmpqqLl3afpfNRXkFp0uXLurXr19EHyMxMZH/eKKAfY4O9jk62OfoYa+jIxL7fL4rN2fxJmMAAGAOgQMAAMwhcL5lXq9X8+bNk9fr7eylmMY+Rwf7HB3sc/Sw19FxIezzRfkmYwAAYBtXcAAAgDkEDgAAMIfAAQAA5hA4AADAHAKnA1asWKH09HQlJCQoIyNDlZWVbc6vqKhQRkaGEhISNHDgQK1atSpKK41t4ezzK6+8optuukmXX365EhMTlZ2drb/+9a9RXG3sCvfP81nvvPOO4uLi9IMf/CCyCzQi3H1uamrS3Llz1b9/f3m9Xl111VVas2ZNlFYbu8Ld57Vr1+raa69Vjx491LdvX9133306cuRIlFYbm/72t7/p1ltvVWpqqjwej1599dXzHtMpz4MOYXnxxRddfHy8W716tduzZ4+bPn26u+SSS9y+fftanf/RRx+5Hj16uOnTp7s9e/a41atXu/j4ePfyyy9HeeWxJdx9nj59ulu0aJHbvn27++CDD9ycOXNcfHy8+/vf/x7llceWcPf5rGPHjrmBAwe6vLw8d+2110ZnsTGsI/s8YcIEl5WV5crLy11dXZ3btm2be+edd6K46tgT7j5XVla6Ll26uN///vfuo48+cpWVle573/uemzhxYpRXHltKS0vd3Llz3YYNG5wkt3Hjxjbnd9bzIIETppEjR7qCgoKQsSFDhrjZs2e3Ov/RRx91Q4YMCRl78MEH3fXXXx+xNVoQ7j63ZtiwYe6JJ574tpdmSkf3efLkye7xxx938+bNI3DaIdx9fu2115zP53NHjhyJxvLMCHefn3rqKTdw4MCQsWXLlrl+/fpFbI3WtCdwOut5kJeownDixAnt3LlTeXl5IeN5eXnasmVLq8dUVVW1mD9mzBjt2LFDJ0+ejNhaY1lH9vmbTp8+rcbGRl122WWRWKIJHd3nZ599Vh9++KHmzZsX6SWa0JF93rRpkzIzM7V48WJdccUVuvrqq/XII4/o66+/jsaSY1JH9jknJ0effPKJSktL5ZzTZ599ppdfflk333xzNJZ80eis58GL8h/b7Kj6+no1NzcrOTk5ZDw5OVl+v7/VY/x+f6vzT506pfr6evXt2zdi641VHdnnb/rtb3+rr776SnfccUcklmhCR/b5X//6l2bPnq3KykrFxfG/j/boyD5/9NFHevvtt5WQkKCNGzeqvr5eDz30kL744gveh3MOHdnnnJwcrV27VpMnT9a///1vnTp1ShMmTNAf/vCHaCz5otFZz4NcwekAj8cT8rNzrsXY+ea3No5Q4e7zWevWrdP8+fO1fv169enTJ1LLM6O9+9zc3KwpU6boiSee0NVXXx2t5ZkRzp/n06dPy+PxaO3atRo5cqTGjx+vJUuW6LnnnuMqznmEs8979uzRtGnT9Jvf/EY7d+5UWVmZ6urqVFBQEI2lXlQ643mQv4KFISkpSV27dm3xt4HDhw+3qNOzUlJSWp0fFxen3r17R2ytsawj+3zW+vXrdf/99+ull17S6NGjI7nMmBfuPjc2NmrHjh2qrq7Www8/LOnME7FzTnFxcdq8ebN+/OMfR2XtsaQjf5779u2rK664Qj6fLzg2dOhQOef0ySefaNCgQRFdcyzqyD4XFRXphhtu0K9+9StJ0jXXXKNLLrlEubm5+t///V+usH9LOut5kCs4YejWrZsyMjJUXl4eMl5eXq6cnJxWj8nOzm4xf/PmzcrMzFR8fHzE1hrLOrLP0pkrN/fee69eeOEFXkNvh3D3OTExUe+//75qamqCt4KCAg0ePFg1NTXKysqK1tJjSkf+PN9www06ePCgvvzyy+DYBx98oC5duqhfv34RXW+s6sg+Hz9+XF26hD4Ndu3aVdL/XWHAf6/Tngcj+hZmg85+DLGkpMTt2bPHzZgxw11yySXu448/ds45N3v2bJefnx+cf/bjcTNnznR79uxxJSUlfEy8HcLd5xdeeMHFxcW55cuXu0OHDgVvx44d66xTiAnh7vM38Smq9gl3nxsbG12/fv3c7bff7nbv3u0qKircoEGD3AMPPNBZpxATwt3nZ5991sXFxbkVK1a4Dz/80L399tsuMzPTjRw5srNOISY0Nja66upqV11d7SS5JUuWuOrq6uDH8S+U50ECpwOWL1/u+vfv77p16+ZGjBjhKioqgr+755573KhRo0Lmv/XWW+66665z3bp1cwMGDHArV66M8opjUzj7PGrUKCepxe2ee+6J/sJjTLh/nv8TgdN+4e5zbW2tGz16tOvevbvr16+fKywsdMePH4/yqmNPuPu8bNkyN2zYMNe9e3fXt29f97Of/cx98sknUV51bHnzzTfb/P/thfI86HGO63AAAMAW3oMDAADMIXAAAIA5BA4AADCHwAEAAOYQOAAAwBwCBwAAmEPgAAAAcwgcAABgDoEDAADMIXAAAIA5BA4AADCHwAEAAOb8f5HuqUla+E88AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "vector = np.array(vector)\n",
    "counts, bins = np.histogram(vector)\n",
    "plt.stairs(counts, bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15aa18c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44c500b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m test_examples \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 2\u001b[0m reconstruction, mu, logvar \u001b[38;5;241m=\u001b[39m model(test_examples)\n\u001b[1;32m      3\u001b[0m reconstruction \u001b[38;5;241m=\u001b[39m reconstruction\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m reconstruction \u001b[38;5;241m=\u001b[39m reconstruction\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "test_examples = img.to(device)\n",
    "reconstruction, mu, logvar = model(test_examples)\n",
    "reconstruction = reconstruction.to('cpu')\n",
    "reconstruction = reconstruction.to('cpu')\n",
    "print(img.shape)\n",
    "print(reconstruction.shape)\n",
    "with torch.no_grad():\n",
    "    number = 1\n",
    "    plt.figure(figsize=(40, 10))\n",
    "    for index in range(number):\n",
    "        # display original\n",
    "        ax = plt.subplot(2, number, index+1)\n",
    "        test_examples = test_examples.to('cpu')\n",
    "        image1 = test_examples[index].permute(1, 2, 0).detach().numpy().clip(0, 1)\n",
    "        plt.imshow(image1)\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        # display reconstruction\n",
    "        ax = plt.subplot(2, number, 2*(index + 1))\n",
    "        image2 = reconstruction[index].permute(1, 2, 0).detach().numpy().clip(0, 1)\n",
    "        plt.imshow(image2)\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b4d066",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(celeba_test_dataset, batch_size=36, shuffle=True)\n",
    "img = next(iter(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd67766f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_examples = img.to(device)\n",
    "reconstruction, mu, logvar = model(test_examples)\n",
    "reconstruction = reconstruction.to('cpu')\n",
    "reconstruction = reconstruction.to('cpu')\n",
    "print(img.shape)\n",
    "print(reconstruction.shape)\n",
    "vutils.save_image(reconstruction.data,\n",
    "                  os.path.join(\n",
    "                      \"./\",\n",
    "                      f\"recons1.png\"),\n",
    "                  normalize=True,\n",
    "                  nrow=6)\n",
    "vutils.save_image(test_examples.data,\n",
    "                  os.path.join(\n",
    "                      \"./\",\n",
    "                      f\"img1.png\"),\n",
    "                  normalize=True,\n",
    "                  nrow=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "584fd4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c75d3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import numpy as np\n",
    "# Choose just one image to display from the batch\n",
    "img = img.to(device)\n",
    "img1, mu, logvar = model(img)\n",
    "img1 = img1.to('cpu')\n",
    "batch_tensor = (img1 - img1.min()) / (img1.max() - img1.min())\n",
    "batch_tensor = batch_tensor.to('cpu')\n",
    "# Create a grid for displaying multiple images\n",
    "fig, axs = plt.subplots(batch_size, figsize=(40,40))\n",
    "\n",
    "# Loop through the batch and display each image\n",
    "for i in range(batch_size):\n",
    "    image1 = batch_tensor[i].permute(1, 2, 0).detach().numpy().clip(0, 1)\n",
    "#     axs[ i] = img[i].permute(1, 2, 0).detach().numpy().clip(0, 1)\n",
    "    axs[i].imshow(image1)\n",
    "    axs[i].axis('off')\n",
    "#     axs[i,1].imshow(image2)\n",
    "#     axs[i,1].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51523126",
   "metadata": {},
   "outputs": [],
   "source": [
    "img[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9e9f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_img = img1[11].permute(1, 2, 0).detach().numpy().clip(0, 1)\n",
    "plt.imshow(p_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
